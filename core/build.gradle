description = "Sparkling Water Core"

apply from: "$rootDir/gradle/utils.gradle"

dependencies {
  // Required for h2o-app (we need UI)
  compile("ai.h2o:h2o-app:${h2oVersion}") {
      //
      // Exclude all dependencies provided by Spark environment already
      // The motivation is to catch error at compile time
      exclude(group: "net.java.dev.jets3t", module: "jets3t")
      exclude(group: "commons-collections", module: "commons-collections")
  }

  // H2O Scala API
  compile "ai.h2o:h2o-scala_${scalaBinaryVersion}:${h2oVersion}"
  // H2O Persistent layer
  compile("ai.h2o:h2o-persist-hdfs:${h2oVersion}") {
      // Cannot use here: transitive = false since Gradle is producing wrong POM file
      // Hence the exlusions are listed manually
      exclude(group: "org.apache.hadoop", module: "hadoop-client")
  }

  // Spark 1.2.0 release
  // - core
  compile "org.apache.spark:spark-core_${scalaBinaryVersion}:${sparkVersion}"
  // - SQL component
  compile "org.apache.spark:spark-sql_${scalaBinaryVersion}:${sparkVersion}"
  // - MLLib component
  compile "org.apache.spark:spark-mllib_${scalaBinaryVersion}:${sparkVersion}"

  // Sparkling Water REPL
  compile(project(':sparkling-water-repl'))

  // Add joda optional convert library which is required in Scala environment
  compile "org.joda:joda-convert:1.7"

  // And Scala library
  compile "org.scala-lang:scala-library:${scalaVersion}"

  // And use scalatest for Scala testing
  testCompile "org.scalatest:scalatest_${scalaBinaryVersion}:2.2.1"
  testCompile "junit:junit:4.11"

  // Integration tests requirements
  integTestCompile "org.scalatest:scalatest_${scalaBinaryVersion}:2.2.1"
  integTestCompile "junit:junit:4.11"

  // Put Spark Assembly on runtime path
  integTestRuntime fileTree(dir: new File((String) sparkHome, "lib/"), include: '*.jar' )
}

// Setup test environment for Spark
test {
    // Test environment
    systemProperty "spark.testing",   "true"

    systemProperty "spark.ext.h2o.node.log.dir", new File(project.getBuildDir(), "h2ologs-test/nodes")
    systemProperty "spark.ext.h2o.client.log.dir", new File(project.getBuildDir(), "h2ologs-test/client")

    // Run with assertions ON
    enableAssertions = true

    // For a new JVM for each test class
    forkEvery = 1

    // Increase heap size
    maxHeapSize = "4g"

    // Increase PermGen
    jvmArgs '-XX:MaxPermSize=384m'

    // Working dir will be root project
    workingDir = rootDir
}

task createSparkVersionFile << {
    File version_file = file("src/main/resources/spark.version")
    version_file.write(sparkVersion)
}

test.dependsOn testJar
processResources.dependsOn createSparkVersionFile

integTest {
    // Pass references to libraries to test launcher
    systemProperty "spark.testing",   "true"
    systemProperty "spark.test.home", "${sparkHome}"
    systemProperty "sparkling.test.hdp.version", "${hdpVersion}"

    // Pass list of jars required for testing
    systemProperty "sparkling.assembly.jar", "${project(":sparkling-water-assembly").configurations.shadow.artifacts.file.join(',')}"
    systemProperty "sparkling.itest.jar", "${integTestJar.archivePath}"
}

