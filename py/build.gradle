description = "PySparkling - Sparkling Water Python Package"

apply from: "$rootDir/gradle/utils.gradle"
apply plugin: 'ru.vyarus.use-python'

import ru.vyarus.gradle.plugin.python.cmd.Python

def getPythonVersion() {
    Python p = new Python(project, python.getPythonPath(), python.getPythonBinary())
    return p.version
}

ext {
    FS = File.separator
    FPS = File.pathSeparator
    pkgDir = file("$buildDir/pkg")
    distDir = file("$buildDir/dist")
    condaDir = file("$buildDir/conda/h2o_pysparkling_${sparkMajorVersion}")
}

// Define the environment required to run tests
python {
    if (project.hasProperty("pythonExec")) {
        pythonBinary project.findProperty("pythonExec").toString()
    }
    pip "tabulate:0.8.3"
    pip "requests:2.21.0"
    pip "future:0.17.1"
    pip "colorama:0.3.8"
    pip "six:1.12.0"
    pip "numpy:1.16.2"
    pip "pyspark:${sparkVersion}"
    envPath "${rootDir.toString()}/.gradle/python/${getPythonVersion()}/${sparkVersion}"
}

configurations {
    mojopipeline
    s3deps
    sparklingWaterAssemblyJar
}

dependencies {
    sparklingWaterAssemblyJar project(path: ':sparkling-water-assembly', configuration: 'shadow')

    if (project.property("testMojoPipeline") == "true") {
        mojopipeline "ai.h2o:mojo2-runtime-impl:${mojoPipelineVersion}"
    }

    s3deps "com.amazonaws:aws-java-sdk:1.7.4"
    s3deps "org.apache.hadoop:hadoop-aws:2.7.3"
}

task resolveTestRuntimeDependencies {
    doLast {
        project.configurations.mojopipeline.resolve()
    }
}

//
// Create a file with version for Python dist task
//
task createVersionFile {
    doLast {
        def versionFileDir = new File(pkgDir, "pysparkling")
        if (!versionFileDir.exists()) {
            versionFileDir.mkdirs()
        }
        File version_file = new File(versionFileDir, "version.txt")
        def version_txt = version.replace("-SNAPSHOT", "")
        version_file.write(version_txt)
    }
}

//
// Represents a location of H2O Wheel Package
//
def h2oPythonWheelPackageLocation = "http://h2o-release.s3.amazonaws.com/h2o/${h2oMajorName != "master" ? "rel-${h2oMajorName}" : "master"}/${h2oBuild}/Python/h2o-${h2oMajorVersion}.${h2oBuild}-py2.py3-none-any.whl"


//
// Initial task checking setup of all properties required
// by Python build
//
task checkPythonEnv {
    doLast {
        def H2O_HOME = System.getenv("H2O_HOME")
        def H2O_PYTHON_WHEEL = System.getenv("H2O_PYTHON_WHEEL")
        def H2O_EXTENDED_JAR = System.getenv("H2O_EXTENDED_JAR")


        if (H2O_HOME == null && H2O_PYTHON_WHEEL == null) {
            throw new InvalidUserDataException("""
    Both properties H2O_HOME and H2O_PYTHON_WHEEL were not found!

    Please specify:
     - H2O_HOME to point to H2O Git repo version ${h2oMajorVersion}.${h2oBuild}
    or
     - H2O_PYTHON_WHEEL to point to downloaded H2O Python Wheel package version ${h2oMajorVersion}.${h2oBuild}
       For example:

        mkdir -p \$(pwd)/private/
        curl -s ${h2oPythonWheelPackageLocation} > \$(pwd)/private/h2o.whl
        export H2O_PYTHON_WHEEL=\$(pwd)/private/h2o.whl
    """)
        }

        // if the spark.ext.h2o.backend.cluster.mode is set to external, then
        // we need to have also H2O_EXTENDED_JAR property set in order to be able to perform tests
        if (detectBackendClusterMode() == "external" && H2O_EXTENDED_JAR == null) {
            throw new InvalidUserDataException("""When running tests on external H2O cluster, H2O_EXTENDED_JAR property is required.

Please set it, for example as:

export H2O_EXTENDED_JAR=`./gradlew -q extendJar -PdownloadH2O`
                                  """)
        }


        if (H2O_HOME != null && H2O_PYTHON_WHEEL != null) {
            logger.info("Both \"H2O_HOME\" and \"H2O_PYTHON_WHEEL\" properties are set. Using \"H2O_HOME\"!")
        }
    }
}

def copyPySetup() {
    def fullVersion = version.replace("-SNAPSHOT", "")
    def (first, second, third) = fullVersion.tokenize(".")
    def majorVersion = "${first}.${second}"

    copy {
        from("$projectDir") {
            include 'setup.py'
        }
        filter {
            it.replaceAll("SUBST_SPARK_MAJOR_VERSION", sparkMajorVersion)
                    .replaceAll("SUBST_SPARK_VERSION", sparkVersion)
                    .replaceAll("SUBST_PYSPARKLING_VERSION", fullVersion)
                    .replaceAll("SUBST_PYSPARKLING_MAJOR_VERSION", majorVersion)
        }
        into pkgDir
    }

    copy {
        from("$projectDir") {
            include 'README.rst'
            include 'MANIFEST.in'
            include 'setup.cfg'
            include 'pysparkling/**/*'
            include 'py_sparkling/**/*'
            exclude '**/*.pyc'
        }
        into pkgDir
    }

    copy {
        from("$projectDir/conda/h2o_pysparkling_SUBST_SPARK_MAJOR_VERSION") {
            include 'bld.bat'
            include 'build.sh'
        }
        into condaDir
    }

    copy {
        from("$projectDir/conda/h2o_pysparkling_SUBST_SPARK_MAJOR_VERSION") {
            include 'meta.yaml'
        }
        filter {
            it.replaceAll("SUBST_SPARK_MAJOR_VERSION", sparkMajorVersion)
                    .replaceAll("SUBST_SPARK_VERSION", sparkVersion)
                    .replaceAll("SUBST_PYSPARKLING_VERSION", fullVersion)
        }
        into condaDir
    }
}


def copyH2OFromH2OHome(String h2oHome) {
    copy {
        from "${h2oHome}/h2o-py/h2o"
        into file("${project.pkgDir}/h2o")
        exclude '**/*.pyc'
        exclude '**/h2o.jar'
    }
}

def copyH2OFromH2OWheel(String h2oPythonWheel) {
    copy {
        from zipTree(h2oPythonWheel)
        into file("${project.pkgDir}")
        include 'h2o/**'
        exclude '**/*.pyc'
        exclude '**/h2o.jar'
    }
}

//
// Make PySparkling distribution zip package
//
task distPython(type: Zip, dependsOn: [checkPythonEnv, configurations.sparklingWaterAssemblyJar]) {
    doFirst {
        def H2O_HOME = System.getenv("H2O_HOME")
        def H2O_PYTHON_WHEEL = System.getenv("H2O_PYTHON_WHEEL")

        // if both properties are set, give precedence to H2O_HOME
        if (H2O_HOME != null && H2O_PYTHON_WHEEL != null) {
            copyH2OFromH2OHome(H2O_HOME)
        } else if (H2O_HOME != null) {
            copyH2OFromH2OHome(H2O_HOME)
        } else if (H2O_PYTHON_WHEEL != null) {
            copyH2OFromH2OWheel(H2O_PYTHON_WHEEL)
        }
        // Copy basic python setup
        copyPySetup()
        def replaceStr =
                """
import zipfile
from os import path

if '.zip' in here:
    try:
        with zipfile.ZipFile(path.dirname(here), 'r') as archive:
            __buildinfo__ = archive.read('h2o/buildinfo.txt').decode('utf-8').strip()
    except:
        __buildinfo__ = "unknown"
else:
    try:
        with open(path.join(here, 'buildinfo.txt'), encoding='utf-8') as f:
            __buildinfo__ = f.read().strip()
    except:
         __buildinfo__ = "unknown"

if '.zip' in here:
    try:
        with zipfile.ZipFile(path.dirname(here), 'r') as archive:
            __version__ = archive.read('h2o/version.txt').decode('utf-8').strip()
    except:
        __version__ = "0.0.local"
else:
    try:
        with open(path.join(here, 'version.txt'), encoding='utf-8') as f:
            __version__ = f.read().strip()
    except:
         __version__ = "0.0.local"
                """

        // Change __init__.py in H2O to be aware of being zipped
        def initFile = file("${project.pkgDir}/h2o/__init__.py")
        def initContent = initFile.readLines()
        def lineStart = initContent.findIndexOf { it == "try:" }
        def lineEnd = initContent.findIndexOf { it == "    __version__ = \"0.0.local\"" }
        if (lineStart != -1 && lineEnd != -1) {
            def before = initContent.subList(0, lineStart).join("\n")
            def full = before + replaceStr + initContent.subList(lineEnd + 1, initContent.size()).join("\n")
            initFile.write(full)
        }

        // Copy sparkling water assembly jar
        def fatJar = configurations.sparklingWaterAssemblyJar.singleFile
        copy {
            from fatJar
            into file("${project.pkgDir}/sparkling_water")
            rename ".*", "sparkling_water_assembly.jar"
        }
        // Save comment into module file
        file("${project.pkgDir}/sparkling_water/").mkdir()
        file("${project.pkgDir}/sparkling_water/__init__.py").write("# Sparkling-water JAR holder for pySparkling module.")
    }
    // Configure proper name
    archiveBaseName = "h2o_pysparkling_${version.substring(0, version.lastIndexOf('.'))}"

    from pkgDir
    destinationDir distDir
}

configurations {
    sdist
}

artifacts {
    sdist distPython
}

def createTestArgs() {
    def args = []
    args.add("${distPython.archiveFile.get()}")
    args.add("spark.ext.h2o.backend.cluster.mode=${detectBackendClusterMode()}")
    
    if (project.property("testMojoPipeline") == "true") {
        args.add("spark.jars=${configurations.mojopipeline.resolve().join(",")}")
    }

    gradle.taskGraph.whenReady {
        if (gradle.taskGraph.hasTask(":${project.name}:hadoopSmokeTests")) {
            args.add("spark.jars=${configurations.s3deps.resolve().join(",")}")
        }
    }

    return args
}

task testPythonConf(type: PythonTask, dependsOn: distPython) {
    extraArgs(*createTestArgs())
    command = "tests/tests_unit_conf.py"
}

task testPythonConversions(type: PythonTask, dependsOn: distPython) {
    extraArgs(*createTestArgs())
    command = "tests/tests_unit_conversions.py"
}

task testPythonMojoPredictions(type: PythonTask, dependsOn: distPython) {
    extraArgs(*createTestArgs())
    command = "tests/tests_unit_mojo_predictions.py"
}


task testPythonMojoPipeline(type: PythonTask, dependsOn: distPython) {
    extraArgs(*createTestArgs())
    command = "tests/tests_unit_mojo_pipeline.py"
}

task hadoopSmokeTests(type: PythonTask, dependsOn: distPython) {
    extraArgs(*createTestArgs())
    command = "tests/tests_hadoop_smoke.py"
}

task testPython(dependsOn: [testPythonConf, testPythonConversions, testPythonMojoPredictions]) {}

if (project.property("testMojoPipeline") == "true") {
    testPython.dependsOn testPythonMojoPipeline
}

//
// Run python integration tests. On Purpose, don't use PythonTask as we want to test the real user
// use case of submitting apps via ./spark-submit
//
task integTestPython(type: Exec, dependsOn: [distPython]) {
    def testEnv = detectTestEnvironment()

    // Pass references to libraries to test launcher
    environment["sparkling.pysparkling.sdist"] = configurations.sdist.artifacts.files.singleFile.absolutePath
    environment['spark.ext.h2o.backend.cluster.mode'] = detectBackendClusterMode()
    // sparkling assembly jar is here because of external h2o tests
    environment["sparkling.assembly.jar"] = configurations.sparklingWaterAssemblyJar.singleFile
    environment["spark.testing"] = "true"
    environment["spark.test.home"] = "${sparkHome}"
    environment["sparkling.test.hdp.version"] = "${hdpVersion}"


    if (sparkMaster != null)
        environment["spark.master"] = "${sparkMaster}"

    // Decide which tests should be launch here based on environment
    switch (testEnv) {
        case "yarn":
            environment["sparkling.test.environment"] = "${testEnv}"
            environment["spark.ext.h2o.node.log.dir"] = "h2ologs-itest-${testEnv}/nodes"
            environment["spark.ext.h2o.client.log.dir"] = "h2ologs-itest-${testEnv}/client"

            commandLine getOsSpecificCommandLine(["tests/tests_integ_yarn.py"])
            break

        case "standalone":
            environment["sparkling.test.environment"] = "${testEnv}"
            environment["spark.ext.h2o.node.log.dir"] = "h2ologs-itest-${testEnv}/nodes"
            environment["spark.ext.h2o.client.log.dir"] = "h2ologs-itest-${testEnv}/client"

            commandLine getOsSpecificCommandLine(["tests/tests_integ_standalone.py"])
            break

        case "local":
            environment["sparkling.test.environment"] = "${testEnv}"
            environment["spark.ext.h2o.node.log.dir"] = new File(project.getBuildDir(), "h2ologs-itest-${testEnv}/nodes").getAbsolutePath()
            environment["spark.ext.h2o.client.log.dir"] = new File(project.getBuildDir(), "h2ologs-itest-${testEnv}/client").getAbsolutePath()

            commandLine getOsSpecificCommandLine(["tests/tests_integ_local.py"])
            break
    }
}

// Run integration tests as part of build
task integTest
integTest.dependsOn integTestPython
check.dependsOn integTest


//
// Just print location of H2O Python Wheel package with respect to a configured version of H2O dependency
//
task printH2OWheelPackage {
    doLast {
        description = "Print location of H2O Python Wheel package for download"
        println(h2oPythonWheelPackageLocation)
    }
}

//
// Cleanup
//
task cleanPython(type: Delete) {
    delete getBuildDir()
}

//
// Setup execution graph
//
clean.dependsOn cleanPython
createVersionFile.dependsOn cleanPython
distPython.dependsOn createVersionFile

// Build tasks
task buildPython(dependsOn: distPython)
build.dependsOn buildPython

test.dependsOn testPython