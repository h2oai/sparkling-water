apply from: "$rootDir/gradle/utils.gradle"

ext {
    FS = File.separator
    FPS = File.pathSeparator
    pythonexec = findProperty("pythonExec") ?: "python"
    pkgDir = file("$buildDir/pkg")
    distDir = file("$buildDir/dist")
}

description = "PySparkling - Sparkling-Water Python Package"

dependencies {
    compile project(path: ':sparkling-water-assembly')
}
//
// Create a file with version for Python dist task
//
task createVersionFile {
    doLast {
        def versionFileDir = new File(pkgDir, "pysparkling")
        if (!versionFileDir.exists()) {
            versionFileDir.mkdirs()
        }
        File version_file = new File(versionFileDir, "version.txt")
        def version_txt = version.replace("-SNAPSHOT","")
        version_file.write(version_txt)
    }
}

//
// Represents a location of H2O Wheel Package
//
def h2oPythonWheelPackageLocation = "http://h2o-release.s3.amazonaws.com/h2o/${h2oMajorName != "master" ? "rel-${h2oMajorName}" : "master"}/${h2oBuild}/Python/h2o-${h2oMajorVersion}.${h2oBuild}-py2.py3-none-any.whl"

//
// Prepare Python environment to execute python commands
//
def preparePythonEnv(environment) {
    def SPARK_HOME = ext.sparkHome
    def py4jDir = "${SPARK_HOME}${FS}python${FS}lib"
    def py4jFile = fileTree(dir: py4jDir, include: 'py4j-*-src.zip').singleFile
    if (SPARK_HOME != null) {
        environment['PYTHONPATH'] = "${SPARK_HOME}${FS}python${FPS}${py4jFile}${FPS}${environment['PYTHONPATH']}"
    }
}

//
// Prepare Python environment to run python tests
//
def preparePythonTestEnv(environment){
    // Add PySparkling zip on PYTHONPATH so unittests can access all the PySparkling packages
    environment['PYTHONPATH'] = "${distPython.archivePath}${FPS}${environment['PYTHONPATH']}"
    environment['spark.ext.h2o.backend.cluster.mode'] = detectBackendClusterMode()
    environment["spark.ext.h2o.external.start.mode"] = detectExternalBackendStartMode()
    // sparkling assembly jar is here because of external h2o tests
    environment["sparkling.assembly.jar"] = configurations.compile.join(',')

    environment['SPARK_WORKER_DIR'] = file('build/h2ologs-pyunit/nodes')
    environment['SPARK_CONF_DIR'] = file("tests/conf/pyunit")
}

//
// Initial task checking setup of all properties required
// by Python build
//
task checkPythonEnv {
    doLast {
        def SPARK_HOME = sparkHome
        def H2O_HOME = System.getenv("H2O_HOME")
        def H2O_PYTHON_WHEEL = System.getenv("H2O_PYTHON_WHEEL")
        def H2O_EXTENDED_JAR = System.getenv("H2O_EXTENDED_JAR")

        if (SPARK_HOME == null) throw new InvalidUserDataException("SPARK_HOME needs to be defined!")

        if (H2O_HOME == null && H2O_PYTHON_WHEEL == null) {
            throw new InvalidUserDataException("""
    Both properties H2O_HOME and H2O_PYTHON_WHEEL were not found!

    Please specify:
     - H2O_HOME to point to H2O Git repo version ${h2oMajorVersion}.${h2oBuild}
    or
     - H2O_PYTHON_WHEEL to point to downloaded H2O Python Wheel package version ${h2oMajorVersion}.${h2oBuild}
       For example:

        mkdir -p \$(pwd)/private/
        curl -s ${h2oPythonWheelPackageLocation} > \$(pwd)/private/h2o.whl
        export H2O_PYTHON_WHEEL=\$(pwd)/private/h2o.whl
    """)
        }

        // if the spark.ext.h2o.backend.cluster.mode is set to external, then
        // we need to have also H2O_EXTENDED_JAR property set in order to be able to perform tests
        if (detectBackendClusterMode() == "external" && H2O_EXTENDED_JAR == null) {
            throw new InvalidUserDataException("""When running tests on external H2O cluster, H2O_EXTENDED_JAR property is required.

Please set it, for example as:

export H2O_EXTENDED_JAR=`./gradlew -q extendJar -PdownloadH2O`
                                  """)
        }


        if (H2O_HOME != null && H2O_PYTHON_WHEEL != null) {
            logger.info("Both \"H2O_HOME\" and \"H2O_PYTHON_WHEEL\" properties are set. Using \"H2O_HOME\"!")
        }
    }
}

def copyPySetup() {
    copy {
        from("$projectDir") {
            include 'README.rst'
            include 'MANIFEST.in'
            include 'setup.cfg'
            include 'setup.py'
            include 'pysparkling/**/*'
            exclude '**/*.pyc'
        }
        into pkgDir
    }
}

def copyH2OFromH2OHome(String h2oHome) {
        copy {
            from "${h2oHome}/h2o-py/h2o"
            into file("${project.pkgDir}/h2o")
            exclude '**/*.pyc'
            exclude '**/h2o.jar'
        }
}

def copyH2OFromH2OWheel(String h2oPythonWheel) {
        copy {
            from zipTree(h2oPythonWheel)
            into file("${project.pkgDir}")
            include 'h2o/**'
            exclude '**/*.pyc'
            exclude '**/h2o.jar'
        }
}

//
// Make PySparkling distribution zip package
//
task distPython(type: Zip, dependsOn: [checkPythonEnv, configurations.compile] ) {
    doFirst {
        def H2O_HOME = System.getenv("H2O_HOME")
        def H2O_PYTHON_WHEEL = System.getenv("H2O_PYTHON_WHEEL")

        // if both properties are set, give precedence to H2O_HOME
        if (H2O_HOME !=null && H2O_PYTHON_WHEEL !=null) {
            copyH2OFromH2OHome(H2O_HOME)
        } else if (H2O_HOME != null) {
            copyH2OFromH2OHome(H2O_HOME)
        } else if (H2O_PYTHON_WHEEL != null) {
            copyH2OFromH2OWheel(H2O_PYTHON_WHEEL)
        }
        // Copy basic python setup
        copyPySetup()

        def replaceStr =
                """
import zipfile
from os import path

__version__ = "0.0.local"
if '.zip' in here:
    with zipfile.ZipFile(path.dirname(here), 'r') as archive:
        __version__ = archive.read('h2o/version.txt').decode('utf-8').strip()
else:
    with open(path.join(here, 'version.txt'), encoding='utf-8') as f:
        __version__ = f.read().strip()

if '.zip' in here:
    with zipfile.ZipFile(path.dirname(here), 'r') as archive:
        __buildinfo__ = archive.read('h2o/buildinfo.txt').decode('utf-8').strip()
else:
    with open(path.join(here, 'buildinfo.txt'), encoding='utf-8') as f:
        __buildinfo__ = f.read().strip()
                """

        // Change __init__.py in H2O to be aware of being zipped
        def initFile = file("${project.pkgDir}/h2o/__init__.py")
        def initContent = initFile.readLines()
        def lineStart = initContent.findIndexOf {it == "with open(os.path.join(here, 'buildinfo.txt'), encoding='utf-8') as f:"}
        def lineEnd = initContent.findIndexOf {it == "    __version__ = f.read()"}
        if (lineStart != -1 && lineEnd != -1){
            def before = initContent.subList(0, lineStart).join("\n")
            def full = before + replaceStr + initContent.subList(lineEnd + 1, initContent.size()).join("\n")
            initFile.write(full)
        }


        // Copy sparkling water fatjar
        def fatJarName = "sparkling-water-assembly_${scalaBaseVersion}-${version}-all.jar"
        def fatJar = configurations.compile.filter{
            it.absoluteFile.getName() == fatJarName}.singleFile
        copy {
            from fatJar
            into  file("${project.pkgDir}/sparkling_water")
            rename ".*", "sparkling_water_assembly.jar"
        }
        // Save comment into module file
        file("${project.pkgDir}/sparkling_water/").mkdir()
        file("${project.pkgDir}/sparkling_water/__init__.py").write("# Sparkling-water JAR holder for pySparkling module.")
    }
    // Configure proper name
    baseName = "h2o_pysparkling_${version.substring(0, version.lastIndexOf('.'))}"

    from pkgDir
    destinationDir distDir
}

configurations{
    sdist
}

artifacts {
    sdist distPython
}

task testPythonConf(type: Exec, dependsOn: distPython){
    doFirst {
        preparePythonEnv(environment)
    }
    preparePythonTestEnv(environment)
    commandLine getOsSpecificCommandLine([pythonexec, "tests/tests_unit_conf.py"])
}

task testPythonConversions(type: Exec, dependsOn: distPython){
    doFirst {
        preparePythonEnv(environment)
    }
    preparePythonTestEnv(environment)
    commandLine getOsSpecificCommandLine([pythonexec, "tests/tests_unit_conversions.py"])
}

task testPythonMojoPredictions(type: Exec, dependsOn: distPython){
    doFirst {
        preparePythonEnv(environment)
    }
    preparePythonTestEnv(environment)
    commandLine getOsSpecificCommandLine([pythonexec, "tests/tests_unit_mojo_predictions.py"])
}

//
// Test python against Spark cloud
//
task testPython(dependsOn: [testPythonConf, testPythonConversions, testPythonMojoPredictions]) {}


//
// Run python integration tests
//
task integTestPython(type: Exec, dependsOn: distPython) {
    doFirst {
        preparePythonEnv(environment)
    }
    def testEnv = detectEnvironment()

    // Pass references to libraries to test launcher
    environment["sparkling.pysparkling.sdist"] = configurations.sdist.artifacts.files.singleFile.absolutePath
    environment['spark.ext.h2o.backend.cluster.mode'] = detectBackendClusterMode()
    environment["spark.ext.h2o.external.start.mode"] = detectExternalBackendStartMode()
    // sparkling assembly jar is here because of external h2o tests
    environment["sparkling.assembly.jar"] = configurations.compile.join(',')
    environment["spark.testing"] = "true"
    environment["spark.test.home"] = "${sparkHome}"
    environment["sparkling.test.hdp.version"] = "${hdpVersion}"


    // if this property is set up h2o cluster will be started on yarn instead on local machine
    if(project.hasProperty("startH2OClusterOnYarn")){
        environment["spark.ext.h2o.external.start.mode"] = "auto"
    }

    if (sparkMaster != null)
        environment["spark.master"] = "${sparkMaster}"

    // Decide which tests should be launch here based on environment
    switch (testEnv) {
        case "yarn":
            environment["sparkling.test.environment"] = "${testEnv}"
            environment["spark.ext.h2o.node.log.dir"] = "h2ologs-itest-${testEnv}/nodes"
            environment["spark.ext.h2o.client.log.dir"] =  "h2ologs-itest-${testEnv}/client"

            commandLine getOsSpecificCommandLine([pythonexec, "tests/tests_integ_yarn.py"])
            break

        case "standalone":
            environment["sparkling.test.environment"] = "${testEnv}"
            environment["spark.ext.h2o.node.log.dir"] = "h2ologs-itest-${testEnv}/nodes"
            environment["spark.ext.h2o.client.log.dir"] = "h2ologs-itest-${testEnv}/client"

            commandLine getOsSpecificCommandLine([pythonexec, "tests/tests_integ_standalone.py"])
            break

        case "local":
            environment["sparkling.test.environment"] = "${testEnv}"
            environment["spark.ext.h2o.node.log.dir"] = new File(project.getBuildDir(), "h2ologs-itest-${testEnv}/nodes").getAbsolutePath()
            environment["spark.ext.h2o.client.log.dir"] = new File(project.getBuildDir(), "h2ologs-itest-${testEnv}/client").getAbsolutePath()

            commandLine getOsSpecificCommandLine([pythonexec, "tests/tests_integ_local.py"])
            break
    }
}

// Run integration tests as part of build
task integTest
integTest.dependsOn integTestPython
check.dependsOn integTest

//
// Cleanup
//
task cleanPython(type: Delete) {
    delete getBuildDir()
}

//
// Just print location of H2O Python Wheel package with respect to a configured version of H2O dependency
//
task printH2OWheelPackage {
    doLast {
        description = "Print location of H2O Python Wheel package for download"
        println(h2oPythonWheelPackageLocation)
    }
}

//
// Setup execution graph
//
clean.dependsOn cleanPython
createVersionFile.dependsOn cleanPython
distPython.dependsOn createVersionFile
 
// Build tasks
task buildPython(dependsOn: distPython)
build.dependsOn buildPython

test.dependsOn testPython
def detectEnvironment(defaultEnv = "local") {
    def denv = [ project.hasProperty("sparklingTestEnv") ? project["sparklingTestEnv"] : null,
                    System.properties["sparklingTestEnv"],
                    defaultEnv
    ].find { h -> h!=null } // first match
    // Return env
    logger.info("* Detected '$denv' Sparkling test environment (configure via property 'sparklingTestEnv')")
    denv
}
