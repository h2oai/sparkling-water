apply from: "$rootDir/gradle/utils.gradle"

ext {
    FS = File.separator
    FPS = File.pathSeparator
}


description = "PySparkling - Sparkling-Water Python Package"

dependencies {
  compile project(path: ':sparkling-water-assembly', configuration: 'shadow')
}

//
// Create a file with version for Python dist task
//
task createVersionFile {
    doLast {
        if(!getBuildDir().exists()){
            getBuildDir().mkdir()
        }
        File version_file = new File(getBuildDir(), "version.txt")
        def version_txt = version.replace("-SNAPSHOT","")
        version_file.write(version_txt)
    }
}

//
// Represents a location of H2O Wheel Package
//
def h2oPythonWheelPackageLocation = "http://h2o-release.s3.amazonaws.com/h2o/${h2oMajorName != "master" ? "rel-${h2oMajorName}" : "master"}/${h2oBuild}/Python/h2o-${h2oMajorVersion}.${h2oBuild}-py2.py3-none-any.whl"

//
// Prepare Python environment to execute python commands
//
def preparePythonEnv(environment) {
    def SPARK_HOME = ext.sparkHome
    def py4jDir = "${SPARK_HOME}${FS}python${FS}lib"
    def py4jfile = fileTree(dir: py4jDir, include: 'py4j-*-src.zip').singleFile
    if (SPARK_HOME != null) {
        environment['PYTHONPATH'] = "${SPARK_HOME}${FS}python${FPS}${py4jfile}${FPS}${environment['PYTHONPATH']}"
    }
}

//
// Initial task checking setup of all properties required
// by Python build
//
task checkPythonEnv {
    doLast {
        def SPARK_HOME = sparkHome
        def H2O_HOME = System.getenv("H2O_HOME")
        def H2O_PYTHON_WHEEL = System.getenv("H2O_PYTHON_WHEEL")
        def H2O_EXTENDED_JAR = System.getenv("H2O_EXTENDED_JAR")

        if (SPARK_HOME == null) throw new InvalidUserDataException("SPARK_HOME needs to be defined!")

        if (H2O_HOME == null && H2O_PYTHON_WHEEL == null) {
            throw new InvalidUserDataException("""
    Both properties H2O_HOME and H2O_PYTHON_WHEEL were not found!

    Please specify:
     - H2O_HOME to point to H2O Git repo version ${h2oMajorVersion}.${h2oBuild}
    or
     - H2O_PYTHON_WHEEL to point to downloaded H2O Python Wheel package version ${h2oMajorVersion}.${h2oBuild}
       For example:

        mkdir -p \$(pwd)/private/
        curl -s ${h2oPythonWheelPackageLocation} > \$(pwd)/private/h2o.whl
        export H2O_PYTHON_WHEEL=\$(pwd)/private/h2o.whl
    """)
        }

        // if the spark.ext.h2o.backend.cluster.mode is set to external, then
        // we need to have also H2O_EXTENDED_JAR property set in order to be able to perform tests
        if (detectBackendClusterMode() == "external" && H2O_EXTENDED_JAR == null) {
            throw new InvalidUserDataException("""When running tests on external H2O cluster, H2O_EXTENDED_JAR property is required.

Please set it, for example as:

export H2O_EXTENDED_JAR=`./gradlew -q extendJar -PdownloadH2O`
                                  """)
        }


        if (H2O_HOME != null && H2O_PYTHON_WHEEL != null) {
            logger.info("Both \"H2O_HOME\" and \"H2O_PYTHON_WHEEL\" properties are set. Using \"H2O_HOME\"!")
        }
    }
}

def copyH2OFromH2OHome(String H2O_HOME){
        copy {
            from "${H2O_HOME}/h2o-py/h2o"
            into file("${project.buildDir}/h2o")
        }
}

def copyH2OFromH2OWheel(String H2O_PYTHON_WHEEL){
        copy {
            from zipTree(H2O_PYTHON_WHEEL)
            into project.buildDir
            include 'h2o/**'
        }
}

//
// Make PySparkling distribution egg package
//
task distPython(type: Exec, dependsOn: checkPythonEnv) {
    doFirst {
        preparePythonEnv(environment)
        def H2O_HOME = System.getenv("H2O_HOME")
        def H2O_PYTHON_WHEEL = System.getenv("H2O_PYTHON_WHEEL")

        if (H2O_HOME !=null && H2O_PYTHON_WHEEL !=null) {
            // if both properties are set, give precedence to H2O_HOME
            copyH2OFromH2OHome(H2O_HOME)
        } else if (H2O_HOME!=null) {
            copyH2OFromH2OHome(H2O_HOME)
        } else if (H2O_PYTHON_WHEEL!=null) {
            copyH2OFromH2OWheel(H2O_PYTHON_WHEEL)
        }

        copy {
            from "${configurations.compile.join(',')}"
            into  file("${project.buildDir}/sparkling_water")
            rename ".*", "sparkling_water_assembly.jar"
        }
        // Save comment into module file
        file("${project.buildDir}${FS}sparkling_water${FS}__init__.py").write("#Sparkling-water JAR holder for pySparkling module.")
    }
    commandLine getOsSpecificCommandLine(["python", "setup.py", "egg_info", "--egg-base=${buildDir.absolutePath}", "bdist_egg",  "--dist-dir=${buildDir.absolutePath}${FS}dist", ])
}

configurations{
    eggs
}

artifacts {
    eggs file("${project.buildDir}/dist/h2o_pysparkling_${version.substring(0, version.lastIndexOf('.'))}-${version.replace("-SNAPSHOT","")}-py2.7.egg").getAbsoluteFile()
}

//
// Test python against Spark cloud
//
task testPython(type: Exec, dependsOn: [configurations.compile, distPython] ) {
    doFirst {
        preparePythonEnv(environment)
    }
    // add PySparkling egg on PYTHONPATH so unittests can see all the modules within this egg file
    environment['PYTHONPATH'] = configurations.eggs.artifacts.files.singleFile.absolutePath +  File.pathSeparator + environment['PYTHONPATH']
    environment['spark.ext.h2o.backend.cluster.mode'] = detectBackendClusterMode()
    // sparkling assembly jar is here because of external h2o tests
    environment["sparkling.assembly.jar"] = configurations.compile.join(',')

    // if this property is set up h2o cluster will be started on yarn instead on local machine
    if(project.hasProperty("startH2OClusterOnYarn")){
        environment["spark.ext.h2o.external.start.mode"] = "auto"
    }
    
    environment['SPARK_WORKER_DIR'] = file('build/h2ologs-pyunit/nodes')
    environment['SPARK_CONF_DIR'] = file("tests/conf/pyunit")
    commandLine getOsSpecificCommandLine(["python", "tests/tests_unit.py"])
}

//
// Run python integration tests
//
task integTestPython(type: Exec, dependsOn: [configurations.compile, distPython] ) {
    doFirst{
        preparePythonEnv(environment)
    }
    def testEnv = detectEnvironment()

    // Pass references to libraries to test launcher
    environment["sparkling.pysparkling.egg"] = configurations.eggs.artifacts.files.singleFile.absolutePath
    environment['spark.ext.h2o.backend.cluster.mode'] = detectBackendClusterMode()
    // sparkling assembly jar is here because of external h2o tests
    environment["sparkling.assembly.jar"] = configurations.compile.join(',')
    environment["spark.testing"] = "true"
    environment["spark.test.home"] = "${sparkHome}"
    environment["sparkling.test.hdp.version"] = "${hdpVersion}"


    // if this property is set up h2o cluster will be started on yarn instead on local machine
    if(project.hasProperty("startH2OClusterOnYarn")){
        environment["spark.ext.h2o.external.start.mode"] = "auto"
    }

    if (sparkMaster != null)
        environment["spark.master"] = "${sparkMaster}"

    // Decide which tests should be launch here based on environment
    switch (testEnv) {
        case "yarn":
            environment["sparkling.test.environment"] = "${testEnv}"
            environment["spark.ext.h2o.node.log.dir"] = "h2ologs-itest-${testEnv}/nodes"
            environment["spark.ext.h2o.client.log.dir"] =  "h2ologs-itest-${testEnv}/client"

            commandLine getOsSpecificCommandLine(["python", "tests/tests_integ_yarn.py"])
            break

        case "standalone":
            environment["sparkling.test.environment"] = "${testEnv}"
            environment["spark.ext.h2o.node.log.dir"] = "h2ologs-itest-${testEnv}/nodes"
            environment["spark.ext.h2o.client.log.dir"] = "h2ologs-itest-${testEnv}/client"

            commandLine getOsSpecificCommandLine(["python", "tests/tests_integ_standalone.py"])
            break

        case "local":
            environment["sparkling.test.environment"] = "${testEnv}"
            environment["spark.ext.h2o.node.log.dir"] = new File(project.getBuildDir(), "h2ologs-itest-${testEnv}/nodes").getAbsolutePath()
            environment["spark.ext.h2o.client.log.dir"] = new File(project.getBuildDir(), "h2ologs-itest-${testEnv}/client").getAbsolutePath()

            commandLine getOsSpecificCommandLine(["python", "tests/tests_integ_local.py"])
            break
    }
}

// Run integration tests as part of build
task integTest
integTest.dependsOn integTestPython
check.dependsOn integTest

//
// Cleanup
//
task cleanPython(type: Delete) {
    delete getBuildDir()
}

//
// Just print location of H2O Python Wheel package with respect to a configured version of H2O dependency
//
task printH2OWheelPackage {
    doLast {
        description = "Print location of H2O Python Wheel package for download"
        println(h2oPythonWheelPackageLocation)
    }
}

//
// Setup execution graph
//
clean.dependsOn cleanPython
createVersionFile.dependsOn cleanPython
distPython.dependsOn createVersionFile

// Build tasks
task buildPython(dependsOn: distPython)
build.dependsOn buildPython

test.dependsOn testPython

def detectEnvironment(defaultEnv = "local") {
    def denv = [ project.hasProperty("sparklingTestEnv") ? project["sparklingTestEnv"] : null,
                    System.properties["sparklingTestEnv"],
                    defaultEnv
    ].find { h -> h!=null } // first match
    // Return env
    logger.info("* Detected '$denv' Sparkling test environment (configure via property 'sparklingTestEnv')")
    denv
}
