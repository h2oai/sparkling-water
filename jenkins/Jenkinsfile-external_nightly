#!/usr/bin/groovy
@Library('test-shared-library') _

properties(
        [
                pipelineTriggers([cron('H 23 * * *')]),
                buildDiscarder(logRotator(numToKeepStr: '10'))
        ]
)

node('dX-hadoop') {
    // Clean workspace
    sh 'rm -rf *'
    // Get Sparkling Water and save the scm environment variables
    checkout scm
    // Get the script with the pipeline
    def pipeline = load 'jenkins/sparklingWaterPipeline.groovy'

    // Execute the pipeline
    pipeline(params) { p ->
        sparkVersion = "2.2.1"
        runUnitTests = "true"
        runLocalIntegTests = "true"
        runScriptTests = "true"
        runIntegTests = "true"
        runPySparklingIntegTests = "true"
        sparklingTestEnv = "yarn"
        buildAgainstH2OBranch = "false"
        h2oBranch = "master"
        buildAgainstSparkBranch = "false"
        sparkBranch = "master"
        hadoopVersion = "2.6"
        backendMode = "external"
        hdpVersion = "2.2.6.3-1"
        driverHadoopVersion = "hdp2.2"
        buildNightly = "true"
        // We have 2 nightly jobs - for external and internal cluster for testing purposes,
        // however it is sufficient to create nightly just after one of these jobs finish
        // We therefore don't publish nightly here, but in the internal nightly job.
        // Note: We can do that as these 2 jobs run at the same time
        uploadNightly = "false"

    }
}
