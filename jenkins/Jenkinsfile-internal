#!/usr/bin/groovy
@Library('test-shared-library') _

// Job parameters
properties(
        [
                parameters(
                        [
                                choice(name: 'sparkVersion',
                                        choices: '2.3.0',
                                        description: 'Version of Spark used for testing.'),

                                booleanParam(name: 'runUnitTests', defaultValue: true, description: 'Run unit tests'),
                                booleanParam(name: 'runPyUnitTests', defaultValue: true, description: 'Run PyUnit tests'),
                                booleanParam(name: 'runLocalIntegTests', defaultValue: true, description: 'Run local integration tests'),
                                booleanParam(name: 'runLocalPyIntegTests', defaultValue: true, description: 'Run local Python integration tests'),
                                booleanParam(name: 'runScriptTests', defaultValue: true, description: 'Run script tests'),
                                booleanParam(name: 'runIntegTests', defaultValue: false, description: 'Run integration tests'),
                                booleanParam(name: 'runPySparklingIntegTests', defaultValue: true, description: 'Run pySparkling integration tests'),

                                choice(
                                        choices: 'yarn\nstandalone\nlocal',
                                        description: 'Sparkling water test profile',
                                        name: 'sparklingTestEnv'),

                                string(name: 'hdpVersion', defaultValue: '2.2.6.3-1', description: 'HDP version to pass to Spark configuration - for example, 2.2.0.0-2041, or 2.6.0.2.2, or current. When running external tests on yarn, the current will not do since it is not automatically expanded -> so please set 2.2.6.3-1'),

                                booleanParam(name: 'buildAgainstH2OBranch', defaultValue: false, description: 'By default, Sparkling Water is built with the included H2O. This option may be used to force build to use specific H2O branch against which Sparkling Water is built.'),
                                string(name: 'h2oBranch', defaultValue: 'master', description: 'H2O branch to build against if buildAgainstH2OBranch is set to true'),
                                booleanParam(name: 'buildAgainstSparkBranch', defaultValue: false, description: 'By default, Sparkling Water is build against released Spark version. This option may be used to force build to use specific Spark branch against which Sparkling Water is built & tested.'),
                                string(name: 'sparkBranch', defaultValue: 'master', description: 'Spark branch to build against if buildAgainstSparkBranch is set to true')
                        ]
                ),
                buildDiscarder(logRotator(numToKeepStr: '10'))
        ]
)

// Only PR builds have the CHANGE_BRANCH set
if (env.CHANGE_BRANCH != null && env.CHANGE_BRANCH != ''){
    cancelPreviousBuilds()
}

node('docker && micro') {
    docker.withRegistry("https://docker.h2o.ai") {

        // Clean workspace
        cleanWs()

        // Get Sparkling Water and save the scm environment variables
        checkout scm
        // Get the script with the pipeline
        def pipeline = load 'jenkins/sparklingWaterPipeline.groovy'

        // Execute the pipeline
        pipeline(params) { p ->
            sparkVersion = "${p.sparkVersion}"
            runUnitTests = "${p.runUnitTests}"
            runPyUnitTests = "${p.runPyUnitTests}"
            runLocalIntegTests = "${p.runLocalIntegTests}"
            runLocalPyIntegTests = "${p.runLocalPyIntegTests}"
            runScriptTests = "${p.runScriptTests}"
            runIntegTests = "${p.runIntegTests}"
            runPySparklingIntegTests = "${p.runPySparklingIntegTests}"
            sparklingTestEnv = "${p.sparklingTestEnv}"
            buildAgainstH2OBranch = "${p.buildAgainstH2OBranch}"
            h2oBranch = "${p.h2oBranch}"
            buildAgainstSparkBranch = "${p.buildAgainstSparkBranch}"
            sparkBranch = "${p.sparkBranch}"
            hadoopVersion = "2.6"
            backendMode = "internal"
            buildNightly = "false"
            uploadNightly = "false"
            dockerVersion = "1"
        }
    }
}
