description = "Sparkling Water Benchmarks"

apply plugin: 'com.github.johnrengelman.shadow'
apply from: "$rootDir/gradle/shadowRuntime.gradle"
apply from: "$rootDir/gradle/utils.gradle"

dependencies {
    // Sparkling Water libraries
    compile project(":sparkling-water-ml")
    compile project(":sparkling-water-repl")
    compile(project(":sparkling-water-core")) {
        exclude group: "javax.servlet", module: "servlet-api"
    }

    // Spark libraries
    compile "org.apache.spark:spark-core_${scalaBaseVersion}:${sparkVersion}"
    compile "org.apache.spark:spark-sql_${scalaBaseVersion}:${sparkVersion}"
    compile "org.apache.spark:spark-mllib_${scalaBaseVersion}:${sparkVersion}"
    compile "org.apache.spark:spark-repl_${scalaBaseVersion}:${sparkVersion}"
}

shadowJar {
    configurations = [project.configurations.shadowRuntime]

    mergeServiceFiles()

    relocate 'javassist', 'ai.h2o.javassist'
    relocate 'com.google.common', 'ai.h2o.com.google.common'
    relocate 'org.eclipse.jetty', 'ai.h2o.org.eclipse.jetty'
    relocate 'org.eclipse.jetty.orbit', 'ai.h2o.org.eclipse.jetty.orbit'

    from "$project.buildDir/resources/main" include '**/*'
    exclude 'www/flow/packs/test-*/**'
}

task cleanTerraform(type: Delete) {
    delete "build/terraform"
}

task copyTerraform(dependsOn: cleanTerraform) {
    doLast {
        copy {
            from 'src/main/terraform'
            include "**/*.tf"
            into "build/terraform"
        }
        copy {
            from '../templates/src/terraform/aws/modules'
            include "network/*.tf"
            include "emr_security/*.tf"
            into "build/terraform/aws/modules"
        }
    }
}

task substituteTerraform(dependsOn: copyTerraform) {
    doLast {
        def tfBaseDir = "${project.buildDir.toString()}/terraform/aws/"
        def tfScripts = [
            "${tfBaseDir}/variables.tf",
            "${tfBaseDir}/modules/emr_benchmarks_deployment/variables.tf",
            "${tfBaseDir}/modules/emr_benchmarks_deployment/main.tf"]
        tfScripts.each { path ->
            def contents = file(path).getText('UTF-8')
            contents = contents
                .replaceAll("SUBST_PACKAGE_FILE", "$buildDir/libs/sparkling-water-benchmarks_$scalaBaseVersion-$version-all.jar")
                .replaceAll("SUBST_H2O_VERSION_NAME", h2oMajorName)
                .replaceAll("SUBST_H2O_VERSION", h2oVersion)
                .replaceAll("SUBST_H2O_BUILD", h2oBuild)
                .replaceAll("SUBST_SW_VERSION", version.toString())
                .replaceAll("SUBST_SCALA_VERSION", scalaBaseVersion)
                .replaceAll("SUBST_EMR_VERSION", supportedEmrVersion)
            
            file(path).write(contents, 'UTF-8')
        }
    }
}

task cleanOutput(type: Delete) {
    delete "output"
}

task runBenchmarks(dependsOn: [shadowJar, substituteTerraform, cleanOutput]) {
    doLast {
        exec {
            def accessKey = project.property("aws_access_key")
            def secretKey = project.property("aws_secret_key")
            def publicKey = project.property("aws_ssh_public_key")

            environment("aws_access_key", accessKey)
            environment("aws_secret_key", secretKey)
            environment("aws_ssh_public_key", publicKey)
            environment("datasets", "datasets.json")

            commandLine "./run_benchmarks.sh"
        }
    }
}

task runBigDataSparkToH2OConversionBenchmarks(dependsOn: [shadowJar, substituteTerraform, cleanOutput]) {
    doLast {
        exec {
            def accessKey = project.property("aws_access_key")
            def secretKey = project.property("aws_secret_key")
            def publicKey = project.property("aws_ssh_public_key")

            environment("aws_access_key", accessKey)
            environment("aws_secret_key", secretKey)
            environment("aws_ssh_public_key", publicKey)
            environment("aws_instance_type", "m5.4xlarge")
            environment("aws_core_instance_count", "10")
            environment("datasets", "bigDatasets.json")
            environment("other_arguments", "-b DataFrameToH2OFrameConversionBenchmark")
            environment("driver_memory_gb", "8")
            environment("executor_memory_gb", "32")
            environment("run_yarn_internal", "false")
            environment("run_yarn_external", "true")
            environment("run_local_internal", "false")

            commandLine "./run_benchmarks.sh"
        }
    }
}

task runBigDataH2OtoSparkConversionBenchmarks(dependsOn: [shadowJar, substituteTerraform, cleanOutput]) {
    doLast {
        exec {
            def accessKey = project.property("aws_access_key")
            def secretKey = project.property("aws_secret_key")
            def publicKey = project.property("aws_ssh_public_key")

            environment("aws_access_key", accessKey)
            environment("aws_secret_key", secretKey)
            environment("aws_ssh_public_key", publicKey)
            environment("aws_instance_type", "m5.4xlarge")
            environment("aws_core_instance_count", "10")
            environment("datasets", "bigDatasets.json")
            environment("other_arguments", "-b H2OFrameToDataFrameConversionBenchmark")
            environment("driver_memory_gb", "8")
            environment("executor_memory_gb", "32")
            environment("run_yarn_internal", "false")
            environment("run_yarn_external", "true")
            environment("run_local_internal", "false")

            commandLine "./run_benchmarks.sh"
        }
    }
}

substituteTerraform.dependsOn build