apply plugin: 'scala'
apply plugin: 'java-library'
apply from: "$rootDir/gradle/utils.gradle"

// Monkey patch the scala compile options to make Idea happy
// See: https://discuss.gradle.org/t/idea-integration-with-scala-plugin-broken-since-gradle-3-0-no-such-property-daemonserver/19159/2
ScalaCompileOptions.metaClass.daemonServer = true
ScalaCompileOptions.metaClass.fork = true
ScalaCompileOptions.metaClass.useAnt = false
ScalaCompileOptions.metaClass.useCompileDaemon = false

configurations {
    scalaCompilerPlugin
}

dependencies {
    scalaCompilerPlugin "org.scalamacros:paradise_${scalaVersion}:2.1.1"
}


// Activate Zinc compiler and configure scalac
tasks.withType(ScalaCompile) {
    scalaCompileOptions.additionalParameters = [
            "-target:jvm-${minSupportedJavaVersion}".toString(),
            "-feature",
            // enable several optional scala features so Scala knows we use them on purpose
            "-language:reflectiveCalls",
            "-language:postfixOps",
            "-language:existentials",
            "-language:implicitConversions",
            "-Xplugin:" + configurations.scalaCompilerPlugin.asPath
    ]
}

java {
    disableAutoTargetJvm()
    sourceCompatibility = JavaVersion.valueOf("VERSION_${minSupportedJavaVersion.replace(".", "_")}")
    targetCompatibility = JavaVersion.valueOf("VERSION_${minSupportedJavaVersion.replace(".", "_")}")
}

project.archivesBaseName = "${project.name}_${scalaBaseVersion}"

project.tasks.withType(AbstractArchiveTask) { AbstractArchiveTask task ->
    task.archiveBaseName = "${project.name}_${scalaBaseVersion}"
}

// Create jar
task testJar(type: Jar, dependsOn: testClasses) {
    group = "Build"
    description = "Assembles a jar archive with test classes."
    archiveBaseName = "${project.name}_${scalaBaseVersion}"
    archiveAppendix = 'test'
    from sourceSets.test.output
}

// Sources Jar generation
task sourcesJar(type: Jar) {
    archiveClassifier = 'sources'
    from sourceSets.main.allSource
}

// Javadoc Jar generation
task javadocJar(type: Jar, dependsOn: javadoc) {
    archiveClassifier = 'javadoc'
    from javadoc.destinationDir
}

task scaladocJar(type: Jar, dependsOn: scaladoc) {
    archiveClassifier = 'scaladoc'
    from scaladoc
}

// Create a configuration containing only for test artifacts
configurations {
    publishArchives
    testArchives
}

artifacts {
    publishArchives sourcesJar
    publishArchives javadocJar
    publishArchives scaladocJar
}

// Explicitly
artifacts {
    testArchives testJar
}

test {
    maxParallelForks = 1
    // Also setup expected Scala version for Spark launcher
    environment "SPARK_SCALA_VERSION", "$scalaBaseVersion"
}

def configurationsToResolve = [
        "runtimeClasspath",
        "compileClasspath",
        "testCompileClasspath",
        "testRuntimeClasspath",
        "integTestCompileClasspath",
        "integTestRuntimeClasspath"]

task resolveDependencies {
    doLast {
        project.configurations.findAll({ Configuration c -> configurationsToResolve.contains(c.name) }).each({ c -> c.resolve() })
    }
}

//
// Initial task checking setup of all properties required
// by scala tests
//
task checkScalaTestEnv {
    doLast {

        // if the spark.ext.h2o.backend.cluster.mode is set to external, then
        // we need to have also H2O_DRIVER_JAR property set in order to be able to perform tests
        if (detectBackendClusterMode() == "external" && System.getenv("H2O_DRIVER_JAR") == null) {

            throw new InvalidUserDataException("""When running tests on external H2O cluster, H2O_DRIVER_JAR property is required.

Download H2O driver for the corresonding hadoop distribution via the shell script ``./bin/get-h2o-driver.sh`` and
and please set it, for example as:

export H2O_DRIVER_JAR=/path/to/h2o-driver.jar
                                  """)
        }
    }
}

// Override ScalaDoc classpath to look only for classes in the scala output dir preventing several warnings for
// missing elements since we don't use java source dirs
scaladoc {
    classpath = files(project.sourceSets.main.compileClasspath, sourceSets.main.scala.outputDir.absolutePath)
}

check.dependsOn(checkScalaTestEnv)

apply plugin: "com.diffplug.gradle.spotless"

spotless {
    scala {
        scalafmt().configFile("$rootDir/.scalafmt.conf")
    }
}
