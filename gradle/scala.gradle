apply plugin: 'scala'
apply from: "$rootDir/gradle/utils.gradle"

// Activate Zinc compiler and configure scalac
tasks.withType(ScalaCompile) {
    scalaCompileOptions.useCompileDaemon = false
    scalaCompileOptions.useAnt = false
    scalaCompileOptions.additionalParameters = ['-target:jvm-1.6']
}

project.archivesBaseName = "${project.name}_${scalaBaseVersion}"

project.tasks.withType(AbstractArchiveTask) { AbstractArchiveTask task ->
    task.baseName = "${project.name}_${scalaBaseVersion}"
}

// Create jar
task testJar(type: Jar, dependsOn: testClasses) {
    group = "Build"
    description = "Assembles a jar archive with test classes."
    baseName = "${project.name}_${scalaBaseVersion}"
    appendix = 'test'
    from sourceSets.test.output
}

task scaladocJar(type: Jar, dependsOn: scaladoc) {
    classifier = 'scaladoc'
    from scaladoc
}

// Create a configuration containing only for test artifacts
configurations {
    testArchives
}

// Explicitly
artifacts {
    testArchives testJar
    archives scaladocJar
}

test {
    maxParallelForks = 1
}

//
// Initial task checking setup of all properties required
// by scala tests
//
task checkScalaTestEnv << {

    // if the spark.ext.h2o.backend.cluster.mode is set to external, then
    // we need to have also H2O_JAR property set in order to be able to perform
    // tests
    if( detectClusterMode()=="external" && System.getenv("H2O_JAR")==null){

        throw new InvalidUserDataException("""When running tests on external H2O Cluster, H2O_JAR property is required.

Please set it, for example:

mkdir -p \$(pwd)/private/
curl -s ${h2oJarLocation()} > \$(pwd)/private/h2o.zip
unzip h2o.zip
export H2O_JAR=\$(pwd)/private/h2o/h2o.jar
                                  """)
    }
}


check.dependsOn(checkScalaTestEnv)

// Enable scalastyle
apply from: "$rootDir/gradle/scalastyle.gradle"

