// Common functions used by more sub-projects

import groovy.json.JsonSlurper
import org.apache.tools.ant.taskdefs.condition.Os

import java.util.zip.ZipEntry
import java.util.zip.ZipInputStream

def getOsSpecificCommandLine(args) {
    return isWindowsBased() ? ['cmd', '/c'] + args : ['/usr/bin/env'] + args
}

def isWindowsBased() {
    return Os.isFamily(Os.FAMILY_WINDOWS)
}

def detectBackendClusterMode(defaultBackendMode = "internal") {
    String mode = [project.hasProperty("backendMode") ? project["backendMode"] : null,
                   System.properties["backendMode"],
                   defaultBackendMode
    ].find { h -> h != null } // first match
    // Return env

    logger.info("* Test will be running in '$mode' cluster mode (configure via property 'backendMode')")
    return mode
}

//
// Represents location of H2O jar
//
def h2oJarLocation() {
    return "http://h2o-release.s3.amazonaws.com/h2o/${h2oMajorName != "master" ? "rel-${h2oMajorName}" : "master"}/${h2oBuild}/h2o-${h2oMajorVersion}.${h2oBuild}.zip"
}

def getGitHash() {
    def proc = ['git', 'rev-parse', '--verify', 'HEAD'].execute()
    return proc.text.trim()
}

String getGitBranch() {
    def branchName = System.getenv("BRANCH_NAME")
    if (branchName != null) {
        return branchName.toString()
    } else {
        def proc = ['git', 'rev-parse', '--verify', '--abbrev-ref', 'HEAD'].execute()
        return proc.text.trim().toString()
    }
}

def getH2OBranch(h2oMajorName) {
    return h2oMajorName == "master" ? "master" : "rel-${h2oMajorName}"
}

/**
 * Return list of Hadoop distributions for this Sparkling Water
 */
def getSupportedHadoopDistributions(h2oMajorName, h2oBuild) {
    def relName = h2oMajorName != "master" ? "rel-${h2oMajorName}" : "master"

    def buildInfo = "https://s3.amazonaws.com/h2o-release/h2o/${relName}/${h2oBuild}/buildinfo.json".toURL().text
    def jsonResp = new JsonSlurper().parseText(buildInfo)
    // we need to ensure that the distribution names does not contain minor versions
    def distributions = jsonResp.hadoop_distributions.collect { it.distribution }
    return distributions.join(" ")
}

def getSparkSpecificSourceDir(sparkMajorVersion) {
    if (file("src/main/scala_spark_$sparkMajorVersion").exists()) {
        return ["src/main/scala_spark_$sparkMajorVersion"]
    } else if (file("src/main/scala_spark_others").exists()) {
        return ["src/main/scala_spark_others"]
    } else {
        return []
    }
}

def getSparkSpecificResourceDir(sparkMajorVersion) {
    if (file("src/main/resources_spark_$sparkMajorVersion").exists()) {
        return ["src/main/resources_spark_$sparkMajorVersion"]
    } else if (file("src/main/resources_spark_others").exists()) {
        return ["src/main/resources_spark_others"]
    } else {
        return []
    }
}

def getS3Path() {
    def branch = getGitBranch()
    def formattedSWBranch = branch.replaceAll("/", "-")
    String path
    if (project.hasProperty("buildAgainstH2OBranch")) {
        def h2oBranch = project.property("buildAgainstH2OBranch")
        def formattedH2OBranch = h2oBranch.replaceAll("/", "-")
        path = "${formattedSWBranch}_${formattedH2OBranch}"
    } else {
        def majorVersion = "${version.split("\\.")[0]}.${version.split("\\.")[1]}"
        def relBranch = "rel-${majorVersion}"
        if (branch == relBranch) {
            path = ""
        } else {
            path = "${formattedSWBranch}"
        }
    }
    if (isNightlyBuild.toBoolean()) {
        if (path != "") {
            path = "${path}/nightly"
        } else {
            path = "nightly"
        }
    }

    if (path != "") {
        path = "${path}/"
    }
    return path
}

String downloadH2ODriverJar(outputDir, hadoopDist, h2oMajorVersion, h2oBuild, h2oMajorName) {
    def saveDir = file(outputDir)
    saveDir.mkdirs()
    def relName = h2oMajorName != "master" ? "rel-${h2oMajorName}" : "master"
    if (hadoopDist == "standalone") {
        def url = "https://s3.amazonaws.com/h2o-release/h2o/${relName}/${h2oBuild}/Rjar/h2o.jar".toURL()
        def h2oJarFile = new File(saveDir, "h2odriver-${h2oMajorVersion}.${h2oBuild}.jar")
        if (!h2oJarFile.exists()) {
            logger.info("Downloading h2o jar from: $url")
            downloadFile(url, h2oJarFile)
        }
        return h2oJarFile.absolutePath
    } else {
        def url = "https://s3.amazonaws.com/h2o-release/h2o/${relName}/${h2oBuild}/h2o-${h2oMajorVersion}.${h2oBuild}-${hadoopDist}.zip".toURL()

        def h2oJarFile = new File(saveDir, "h2odriver-${h2oMajorVersion}.${h2oBuild}-${hadoopDist}.jar")
        if (!h2oJarFile.exists()) {
            def zipEntryName = "h2o-${h2oMajorVersion}.${h2oBuild}-${hadoopDist}/h2odriver.jar"

            def distributions = getSupportedHadoopDistributions(h2oMajorName, h2oBuild)
            if (!distributions.contains(hadoopDist)) {
                throw new IOException("""
The hadoop version you have specified is $hadoopDist, however supported hadoop versions are $distributions
""")
            }
            logger.info("Downloading h2o driver for hadoop version: $hadoopDist from: $url")
            downloadFileFromZip(url, h2oJarFile, zipEntryName)

        }
        return h2oJarFile.absolutePath
    }
}

/**
 * This method expects URL pointing to a zip file and it will save on disk only a file from that zip
 * with the specified name
 * @param fromZip url pointing to a zip file
 * @param to file to which we store the data
 * @param fullFileName file name in zip file we want to download
 * @return path to the downloaded file
 */
def static downloadFileFromZip(URL fromZip, File to, String fullFileName) {
    fromZip.withInputStream { is ->
        ZipInputStream zin = new ZipInputStream(is)
        ZipEntry ze = zin.getNextEntry()
        // read the files before we hit the one we are interested in
        while (ze.getName() != fullFileName) {
            zin.closeEntry()
            ze = zin.getNextEntry()
        }
        saveFile(zin, to)
        zin.closeEntry()
    }
    return to.absolutePath
}

/**
 * Download a file from the provided URL into target file and return path to the downloaded file
 * @param from url from which download the data
 * @param to target file
 * @return path to the downloaded file
 */
def static downloadFile(URL from, File to) {
    from.withInputStream { is ->
        saveFile(is, to)
    }
    return to.absolutePath
}

/**
 * Save data in provided input stream to the specified file
 * @param is input stream with data
 * @param to file to which store the data
 * @return path to the file
 */
def static saveFile(InputStream is, File to) {
    to.withOutputStream { os ->
        def bs = new BufferedOutputStream(os)
        bs << is
    }
    return to.absolutePath
}


// Export methods by turning them into closures
ext {
    getOsSpecificCommandLine = this.&getOsSpecificCommandLine
    isWindowsBased = this.&isWindowsBased
    detectBackendClusterMode = this.&detectBackendClusterMode
    h2oJarLocation = this.&h2oJarLocation
    getGitHash = this.&getGitHash
    getGitBranch = this.&getGitBranch
    getH2OBranch = this.&getH2OBranch
    getSupportedHadoopDistributions = this.&getSupportedHadoopDistributions
    downloadH2ODriverJar = this.&downloadH2ODriverJar
    getSparkSpecificSourceDir = this.&getSparkSpecificSourceDir
    getSparkSpecificResourceDir = this.&getSparkSpecificResourceDir
    getS3Path = this.&getS3Path
}
