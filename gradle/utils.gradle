// Common functions used by more sub-projects

import groovy.json.JsonSlurper
import org.apache.tools.ant.taskdefs.condition.Os

def getOsSpecificCommandLine(args) {
    return isWindowsBased() ? ['cmd', '/c'] + args : ['/usr/bin/env'] + args
}

def isWindowsBased() {
    return Os.isFamily(Os.FAMILY_WINDOWS)
}

def detectBackendClusterMode(defaultBackendMode = "internal") {
    String mode = [project.hasProperty("backendMode") ? project["backendMode"] : null,
                   System.properties["backendMode"],
                   defaultBackendMode
    ].find { h -> h != null } // first match
    // Return env

    logger.info("* Test will be running in '$mode' cluster mode (configure via property 'backendMode')")
    return mode
}

//
// Represents location of H2O jar
//
def h2oJarLocation() {
    return "http://h2o-release.s3.amazonaws.com/h2o/${h2oMajorName != "master" ? "rel-${h2oMajorName}" : "master"}/${h2oBuild}/h2o-${h2oMajorVersion}.${h2oBuild}.zip"
}

def getGitHash() {
    def proc = ['git', 'rev-parse', '--verify', 'HEAD'].execute()
    return proc.text.trim()
}

String getGitBranch() {
    def branchName = System.getenv("BRANCH_NAME")
    if (branchName != null) {
        return branchName.toString()
    } else {
        def proc = ['git', 'rev-parse', '--verify', '--abbrev-ref', 'HEAD'].execute()
        return proc.text.trim().toString()
    }
}

def getH2OBranch(h2oMajorName) {
    return h2oMajorName == "master" ? "master" : "rel-${h2oMajorName}"
}

/**
 * Return list of Hadoop distributions for this Sparkling Water
 */
def getSupportedHadoopDistributions(h2oMajorName, h2oBuild) {
    def relName = h2oMajorName != "master" ? "rel-${h2oMajorName}" : "master"

    def buildInfo = "https://s3.amazonaws.com/h2o-release/h2o/${relName}/${h2oBuild}/buildinfo.json".toURL().text
    def jsonResp = new JsonSlurper().parseText(buildInfo)
    // we need to ensure that the distribution names does not contain minor versions
    def distributions = jsonResp.hadoop_distributions.collect { it.distribution }
    return distributions.join(" ")
}

def getSparkSpecificSourceDir(sparkMajorVersion) {
    if (file("src/main/scala_spark_$sparkMajorVersion").exists()) {
        return ["src/main/scala_spark_$sparkMajorVersion"]
    } else if (file("src/main/scala_spark_others").exists()) {
        return ["src/main/scala_spark_others"]
    } else {
        return []
    }
}

def getSparkSpecificResourceDir(sparkMajorVersion) {
    if (file("src/main/resources_spark_$sparkMajorVersion").exists()) {
        return ["src/main/resources_spark_$sparkMajorVersion"]
    } else if (file("src/main/resources_spark_others").exists()) {
        return ["src/main/resources_spark_others"]
    } else {
        return []
    }
}

def getS3BucketPrefix() {
    def prefix = "sparkling-water/spark-${spark}"

    def branch = getGitBranch()
    def formattedSWBranch = branch.replaceAll("/", "-")
    def path
    if (project.hasProperty("buildAgainstH2OBranch")) {
        def h2oBranch = project.property("buildAgainstH2OBranch")
        def formattedH2OBranch = h2oBranch.replaceAll("/", "-")
        path = "${prefix}/${formattedSWBranch}_${formattedH2OBranch}"
    } else {
        def majorVersion = "${version.split("\\.")[0]}.${version.split("\\.")[1]}"
        def relBranch = "rel-${majorVersion}"
        if (branch == relBranch) {
            path = "${prefix}"
        } else {
            path = "${prefix}/${formattedSWBranch}"
        }
    }
    if (isNightlyBuild) {
        return "${path}/nightly"
    } else {
        return path
    }
}

def getS3Bucket() {
    def prefix = getS3BucketPrefix()
    return "${prefix}/${version}"

}
// Export methods by turning them into closures
ext {
    getOsSpecificCommandLine = this.&getOsSpecificCommandLine
    isWindowsBased = this.&isWindowsBased
    detectBackendClusterMode = this.&detectBackendClusterMode
    h2oJarLocation = this.&h2oJarLocation
    getGitHash = this.&getGitHash
    getGitBranch = this.&getGitBranch
    getH2OBranch = this.&getH2OBranch
    getSupportedHadoopDistributions = this.&getSupportedHadoopDistributions
    getSparkSpecificSourceDir = this.&getSparkSpecificSourceDir
    getSparkSpecificResourceDir = this.&getSparkSpecificResourceDir
    getS3Bucket = this.&getS3Bucket
    getS3BucketPrefix = this.&getS3BucketPrefix
}
