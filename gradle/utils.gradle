// Common functions used by more sub-projects

import groovy.json.JsonSlurper
import org.apache.tools.ant.taskdefs.condition.Os

def getOsSpecificCommandLine(args) {
    return isWindowsBased() ? ['cmd', '/c'] + args : ['/usr/bin/env'] + args
}

def isWindowsBased() {
    return Os.isFamily(Os.FAMILY_WINDOWS)
}

def detectBackendClusterMode(defaultBackendMode = "internal") {
    String mode = [project.hasProperty("backendMode") ? project["backendMode"] : null,
                   System.properties["backendMode"],
                   defaultBackendMode
    ].find { h -> h != null } // first match
    // Return env

    logger.info("* Test will be running in '$mode' cluster mode (configure via property 'backendMode')")
    return mode
}

//
// Represents location of H2O jar
//
def h2oJarLocation() {
    return "http://h2o-release.s3.amazonaws.com/h2o/${h2oMajorName != "master" ? "rel-${h2oMajorName}" : "master"}/${h2oBuild}/h2o-${h2oMajorVersion}.${h2oBuild}.zip"
}

def getGitHash() {
    def proc = ['git', 'rev-parse', '--verify', 'HEAD'].execute()
    return proc.text.trim()
}

String getGitBranch() {
    def branchName = System.getenv("BRANCH_NAME")
    if (branchName != null) {
        return branchName.toString()
    } else {
        def proc = ['git', 'rev-parse', '--verify', '--abbrev-ref', 'HEAD'].execute()
        return proc.text.trim().toString()
    }
}

def getH2OBranch(h2oMajorName) {
    return h2oMajorName == "master" ? "master" : "rel-${h2oMajorName}"
}

/**
 * Return list of Hadoop distributions for this Sparkling Water
 */
def getSupportedHadoopDistributions(h2oMajorName, h2oBuild) {
    def relName = h2oMajorName != "master" ? "rel-${h2oMajorName}" : "master"

    def buildInfo = "https://s3.amazonaws.com/h2o-release/h2o/${relName}/${h2oBuild}/buildinfo.json".toURL().text
    def jsonResp = new JsonSlurper().parseText(buildInfo)
    // we need to ensure that the distribution names does not contain minor versions
    def distributions = jsonResp.hadoop_distributions.collect { it.distribution }
    return distributions.join(" ")
}

def getCurrentRSparklingVersion(def projectDir) {
    def proc = ['R', '-e', "source('for_release/utils.R'); getCurrentVersion(\"src\");"].execute([], file(projectDir))
    def lines = proc.text.readLines()
    def idx = lines.findIndexOf { it.contains("[1]") }
    def patchVersion = lines[idx].replace("[1] ", "").toString()
    return "0.2." + patchVersion
}

def getSparkSpecificSourceDir(sparkMajorVersion) {
    if (file("src/main/scala_spark_$sparkMajorVersion").exists()) {
        return ["src/main/scala_spark_$sparkMajorVersion"]
    } else if (file("src/main/scala_spark_others").exists()) {
        return ["src/main/scala_spark_others"]
    } else {
        return []
    }
}

def getSparkSpecificResourceDir(sparkMajorVersion) {
    if (file("src/main/resources_spark_$sparkMajorVersion").exists()) {
        return ["src/main/resources_spark_$sparkMajorVersion"]
    } else if (file("src/main/resources_spark_others").exists()) {
        return ["src/main/resources_spark_others"]
    } else {
        return []
    }
}

def getPatchVersionNumber() {
    def patchVersion = version.toString().split("\\.")[2]

    if (isNightlyBuild) {
        return patchVersion.split("-")[1]
    } else {
        return patchVersion
    }
}

def getS3Bucket() {
    def prefix = "sparkling-water/${getGitBranch().replaceAll("/", "-")}-${spark}"
    def suffix = getPatchVersionNumber()

    if (isNightlyBuild) {
        return "${prefix}/nightly/${suffix}"
    } else {
        return "${prefix}/${suffix}"
    }
}

// Export methods by turning them into closures
ext {
    getOsSpecificCommandLine = this.&getOsSpecificCommandLine
    isWindowsBased = this.&isWindowsBased
    detectBackendClusterMode = this.&detectBackendClusterMode
    h2oJarLocation = this.&h2oJarLocation
    getGitHash = this.&getGitHash
    getGitBranch = this.&getGitBranch
    getH2OBranch = this.&getH2OBranch
    getSupportedHadoopDistributions = this.&getSupportedHadoopDistributions
    getCurrentRSparklingVersion = this.&getCurrentRSparklingVersion
    getSparkSpecificSourceDir = this.&getSparkSpecificSourceDir
    getSparkSpecificResourceDir = this.&getSparkSpecificResourceDir
    getS3Bucket = this.&getS3Bucket
}
