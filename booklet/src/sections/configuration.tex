\documentclass{standalone}
\usepackage{placeins}
\begin{document}

	\section{Sparkling Water Configuration Properties}
	\label{sec:properties}

	The following configuration properties can be passed to Spark to configure Sparkling Water:

	\subsection{Configuration Properties Independent of Selected Backend}
	\begin{footnotesize}
		\begin{longtable}[!ht]{l p{2.0cm} p{3.0cm}}
			\toprule
			Property name & Default & Description \\
			\midrule

			spark.ext.h2o.backend.cluster.mode & internal & This option can be set either to \texttt{internal} or \texttt{external}. When set to \texttt{external}, H2O Context is created by connecting to existing H2O cluster, otherwise H2O cluster located inside Spark is created. That means that each Spark executor will have one H2O instance running in it. The \texttt{internal} mode is not recommended for big clusters and clusters where Spark executors are not stable. \\ \addlinespace

			spark.ext.h2o.cloud.name & Generated unique name & Name of the H2O cluster. \\ \addlinespace

			spark.ext.h2o.nthreads  & -1 & Limit for number of threads used by H2O, default -1 means: Use value of spark.executor.cores in case this property is set. Otherwise use H2O's default value Runtime.getRuntime() .availableProcessors(). \\ \addlinespace

			spark.ext.h2o.repl.enabled & true & Decides whether H2O REPL is initiated or not. \\ \addlinespace

			spark.ext.scala.int.default.num & 1 & Number of parallel REPL sessions started at the start of Sparkling Water. \\ \addlinespace

			spark.ext.h2o.topology.change.listener.enabled & true &  Decides whether the listener the kills the H2O cluster upon the change of the underlying cluster's topology is enabled or not. \\ \addlinespace

			spark.ext.h2o.spark.version.check.enabled & true & Enables check if run-time Spark version matches build time Spark version. \\ \addlinespace

			spark.ext.h2o.fail.on.unsupported.spark.param & true & If unsupported Spark parameter is detected, then the application is forced to shutdown. \\ \addlinespace

			spark.ext.h2o.jks & None & Path to Java KeyStore file. \\ \addlinespace

			spark.ext.h2o.jks.pass & None & Password for Java KeyStore file. \\ \addlinespace

			spark.ext.h2o.jks.alias & None & Alias to certificate in keystore to secure H2O Flow. \\ \addlinespace

			spark.ext.h2o.hash.login & false & Enable hash login. \\ \addlinespace

			spark.ext.h2o.ldap.login & false & Enable LDAP login. \\ \addlinespace

			spark.ext.h2o.kerberos.login & false & Enable Kerberos login. \\ \addlinespace

			spark.ext.h2o.login.conf & None & Login configuration file. \\ \addlinespace

			spark.ext.h2o.user.name & None & Username used for the backend H2O cluster and to authenticate the client against the backend. \\ \addlinespace

			spark.ext.h2o.password & None & Password used to authenticate the client against the backend. \\ \addlinespace

			spark.ext.h2o.internal\_security\_conf & None & Path to a file containing H2O or Sparkling Water internal security configuration. \\ \addlinespace

			spark.ext.h2o.auto.flow.ssl & false & Automatically generate the required key store and password to secure H2O flow by SSL. \\ \addlinespace

			spark.ext.h2o.node.log.level & INFO & H2O internal log level used for H2O nodes except the client. \\ \addlinespace

			spark.ext.h2o.node.log.dir  & {user.dir}/h2ologs/ {SparkAppId} or YARN container dir & Location of H2O logs on H2O nodes except on the client. \\ \addlinespace

			spark.ext.h2o.backend.heartbeat.interval & 10000ms & Interval for getting heartbeat from the H2O backend. \\ \addlinespace

			spark.ext.h2o.cloud.timeout & 60x1000 & Timeout (in msec) for cluster formation. \\ \addlinespace

			spark.ext.h2o.node.network.mask & None & Subnet selector for H2O running inside Spark executors. This disables using IP reported by Spark but tries to find IP based on the specified mask. \\ \addlinespace

			spark.ext.h2o.stacktrace.collector.interval & -1 & Interval specifying how often stack traces are taken on each H2O node. -1 means that no stack traces will be taken. \\ \addlinespace

			spark.ext.h2o.context.path & None & Context path to expose H2O web server. \\ \addlinespace

			spark.ext.h2o.flow.scala.cell.async & false & Decide whether the Scala cells in H2O Flow will run synchronously or Asynchronously. Default is synchronously. \\ \addlinespace

			spark.ext.h2o.flow.scala.cell.max.parallel & -1 & Number of max parallel Scala cell jobs The value -1 means not limited. \\ \addlinespace

			spark.ext.h2o.internal.port.offset & 1 & Offset between the API(=web) port and the internal communication port on the client node; api\_port + port\_offset = h2o\_port. \\ \addlinespace

			spark.ext.h2o.node.port.base & 54321 & Base port used for individual H2O nodes. \\ \addlinespace

			spark.ext.h2o.mojo.destroy.timeout & 600000 & If a scoring MOJO instance is not used within a Spark executor JVM for a given timeout in milliseconds, it's evicted from executor's cache. Default timeout value is 10 minutes. \\ \addlinespace

			spark.ext.h2o.node.extra & None & A string containing extra parameters passed to H2O nodes during startup. This parameter should be configured only if H2O parameters do not have any corresponding parameters in Sparkling Water. \\ \addlinespace

			spark.ext.h2o.flow.extra.http.headers & None & Extra HTTP headers that will be used in communication between the front-end and back-end part of Flow UI. The headers should be delimited by a new line. Don't forget to escape special characters when passing the parameter from a command line. \\ \addlinespace

			spark.ext.h2o.internal\_secure\_connections & false & Enables secure communications among H2O nodes. The security is based on automatically generated keystore and truststore. This is equivalent for -internal\_secure\_conections option in H2O Hadoop deployments. \\ \addlinespace

			spark.ext.h2o.allow\_insecure\_xgboost & false & If the property set to true, insecure communication among H2O nodes is allowed for the XGBoost algorithm even if the property spark.ext.h2o .internal\_secure\_connections is set to true. \\ \addlinespace

			spark.ext.h2o.kerberized.hive.enabled & false & If enabled, H2O instances will create JDBC connections to a Kerberized Hive so that all clients can read data from HiveServer2. Don't forget to put a jar with Hive driver on Spark classpath if the internal backend is used. \\ \addlinespace

			spark.ext.h2o.hive.host & None & The full address of HiveServer2, for example hostname:10000. \\ \addlinespace

			spark.ext.h2o.hive.principal & None & Hiveserver2 Kerberos principal, for example hive/hostname@DOMAIN.COM \\ \addlinespace

			spark.ext.h2o.hive.jdbc\_url\_pattern & None & A pattern of JDBC URL used for connecting to Hiveserver2. Example: jdbc:hive2://{{host}}/;{{auth}} \\ \addlinespace

			spark.ext.h2o.hive.token & None & An authorization token to Hive \\ \addlinespace

			spark.ext.h2o.client.flow.dir & None & Directory where flows from H2O Flow are saved. \\ \addlinespace

			spark.ext.h2o.client.ip & None & IP of H2O client node. \\ \addlinespace

			spark.ext.h2o.client.iced.dir & None & Location of iced directory for the driver instance. \\ \addlinespace

			spark.ext.h2o.client.log.level & INFO & H2O internal log level used for H2O client running inside Spark driver. \\  \addlinespace

			spark.ext.h2o.client.log.dir & {user.dir}/h2ologs/ {SparkAppId} & Location of H2O logs on the driver machine. \\  \addlinespace

			spark.ext.h2o.client.port.base & 54321 & Port on which H2O client publishes its API. If already occupied, the next odd port is tried on so on. \\ \addlinespace

			spark.ext.h2o.client.web.port & -1 & Exact client port to access web UI. -1 triggers automatic search for free port starting at spark.ext.h2o.port.base.\\ \addlinespace

			spark.ext.h2o.client.verbose & false & The client outputs verbose log output directly into console. Enabling the flag increases the client log level to INFO. \\ \addlinespace

			spark.ext.h2o.client.network.mask & None & Subnet selector for H2O client, this disables using IP reported by Spark but tries to find IP based on the specified mask. \\ \addlinespace

			spark.ext.h2o.client.flow.baseurl.override & None & Allows to override the base URL address of Flow UI, including the scheme, which is showed to the user. \\ \addlinespace

			spark.ext.h2o.cluster.client.retry.timeout & 60000 & Timeout in milliseconds specifying how often we check whether the the client is still connected. \\ \addlinespace

			spark.ext.h2o.client.extra & None & A string containing extra parameters passed to H2O client during startup. This parameter should be configured only if H2O parameters do not have any corresponding parameters in Sparkling Water. \\ \addlinespace

			spark.ext.h2o.verify\_ssl\_certificates & true & Whether certificates should be verified before using in H2O or not. \\ \addlinespace

			spark.ext.h2o.rest.api.timeout & 3*60*1000 & Timeout in milliseconds for Rest API requests. \\

			\bottomrule
		\end{longtable}
	\end{footnotesize}


	\subsubsection{Internal Backend Configuration Properties}
	\begin{footnotesize}
		\begin{longtable}[!ht]{l p{2.0cm} p{3.0cm}}
			\toprule
			Property name & Default & Description \\
			\midrule

			spark.ext.h2o.cluster.size & None & Expected number of workers of H2O cluster. Value None means automatic detection of cluster size. This number must be equal to number of Spark executors. \\ \addlinespace

			spark.ext.h2o.dummy.rdd.mul.factor & 10 & Multiplication factor for dummy RDD generation. Size of dummy RDD is spark.ext.h2o.cluster.size * spark.ext.h2o.dummy .rdd.mul.factor. \\ \addlinespace

			spark.ext.h2o.spreadrdd.retries & 10 & Number of retries for creation of an RDD spread across all existing Spark executors. \\ \addlinespace

			spark.ext.h2o.default.cluster.size & 20 & Starting size of cluster in case that size is not explicitly configured. \\ \addlinespace

			spark.ext.h2o.subseq.tries & 5 & Subsequent successful tries to figure out size of Spark cluster, which are producing the same number of nodes. \\ \addlinespace

			spark.ext.h2o.hdfs\_conf & sc.hadoopConfig & Either a string with the Path to a file with Hadoop HDFS configuration or the org.apache.hadoop.conf .Configuration object. Useful for HDFS credentials settings and other HDFS-related configurations. \\ \addlinespace

			spark.ext.h2o.spreadrdd.retries.timeout & 0 & Specifies how long the discovering of Spark executors should last. This option has precedence over other options influencing the discovery mechanism.That means that as long as the timeout hasn't expired, we keep trying to discover new executors. This option might be useful in environments where Spark executors might join the cloud with some delays. \\ \addlinespace

			spark.ext.h2o.node.iced.dir & None & Location of iced directory for H2O nodes on the Spark executors. \\ \addlinespace

			\bottomrule
		\end{longtable}
	\end{footnotesize}


	\subsubsection{External Backend Configuration Properties}
	\begin{footnotesize}
		\begin{longtable}[!ht]{l l p{3.0cm}}
			\toprule
			Property name & Default & Description \\
			\midrule

			spark.ext.h2o.cloud.representative & None & IP:port of the leader node of the external H2O cluster. \\ \addlinespace

			spark.ext.h2o.external.cluster.size & None & Number of H2O nodes to start when auto mode of the external backend is set. \\ \addlinespace

			spark.ext.h2o.cluster.start.timeout & 120s & Timeout in seconds for starting H2O external cluster. \\ \addlinespace

			spark.ext.h2o.cluster.info.name & None & Full path to a file which is used sd the notification file for the startup of external H2O cluster. \\ \addlinespace

			spark.ext.h2o.hadoop.memory & 6G & Amount of memory assigned to each H2O node on YARN/Hadoop. \\ \addlinespace

			spark.ext.h2o.external.hdfs.dir & None & Path to the directory on HDFS used for storing temporary files. \\ \addlinespace

			spark.ext.h2o.external.start.mode & manual & If this option is set to \texttt{auto} then H2O external cluster is automatically started using the provided H2O driver JAR on YARN, otherwise it is expected that the cluster is started by the user manually. \\ \addlinespace

			spark.ext.h2o.external.h2o.driver & None & Path to H2O driver used during auto start mode. \\ \addlinespace

			spark.ext.h2o.external.yarn.queue & None & YARN queue on which external H2O cluster is started. \\ \addlinespace

			spark.ext.h2o.external.kill.on.unhealthy & true & If true, the client will try to kill the cluster and then itself in case some nodes in the cluster report unhealthy status. \\ \addlinespace

			spark.ext.h2o.external.kerberos.principal & None & Kerberos Principal. \\ \addlinespace

			spark.ext.h2o.external.kerberos.keytab & None & Kerberos Keytab. \\ \addlinespace

			spark.ext.h2o.external.run.as.user & None & Impersonated Hadoop user. \\ \addlinespace

			spark.ext.h2o.external.driver.if & None & Ip address or network of mapper-driver callback interface. Default value means automatic detection. \\ \addlinespace

			spark.ext.h2o.external.driver.port & None & Port of mapper->driver callback interface. Default value means automatic detection. \\ \addlinespace

			spark.ext.h2o.external.driver.port.range & None & Range portX-portY of mapper-driver callback interface; eg: 50000-55000. \\ \addlinespace

			spark.ext.h2o.external.extra.memory.percent & 10 & This option is a percentage of spark.ext.h2o.hadoop.memory and specifies memory for internal JVM use outside of Java heap. \\ \addlinespace

			spark.ext.h2o.external.backend.stop.timeout & 10000ms & Timeout for confirmation from worker nodes when stopping the external backend. It is also possible to pass -1 to ensure the indefinite timeout. The unit is milliseconds. \\ \addlinespace

			spark.ext.h2o.external.hadoop.executable & hadoop & Name or path to path to a hadoop executable binary which is used to start external H2O backend on YARN. \\ \addlinespace

			spark.ext.h2o.external.extra.jars & None & Comma-separated paths to jars that will be placed onto classpath of each H2O node. \\ \addlinespace

			spark.ext.h2o.external.communication.compression & SNAPPY & The type of compression used for data transfer between Spark and H2O node. Possible values are NONE, DEFLATE, GZIP, SNAPPY. \\
			\bottomrule
		\end{longtable}
	\end{footnotesize}

\end{document}
