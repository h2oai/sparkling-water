\section{Starting Sparkling Water}

This section focuses on how Sparkling Water can be started in both backends and all language clients.
You can submit a Sparkling Water code as a Spark batch job or you can explore its functionality in an interactive shell.

Before you start, please make sure that you have downloaded Sparkling Water from \url{https://www.h2o.ai/download/} for
your desired Spark version.

\subsection{Setting up the Environment}

In the case of Scala, all dependencies are already provided inside the Sparkling Water artifacts.

In the case of Python, please make sure that you have the following Python packages installed:
\begin{itemize}
    \item requests
    \item tabulate
    \item future
    \item colorama\textgreater=0.3.8
\end{itemize}.
Also please make sure that your Python environment is set-up to run regular Spark applications.

In the case of R, please make sure that SparklyR and H2O libraries are installed. The H2O version needs to match the version
used in Sparkling Water. For example, when using RSparkling 3.30.0.7, make sure that you have H2O of version 3.30.0.7 installed.

\subsection{Starting Interactive Shell with Sparkling Water}

To start interactive Scala shell, run:

\begin{lstlisting}[style=bash]
./bin/sparkling-shell
\end{lstlisting}

To start interactive Python shell, run:

\begin{lstlisting}[style=bash]
./bin/pysparkling
\end{lstlisting}

To use RSparkling in an interactive environment, we suggest using RStudio.

\subsection{Starting Sparkling Water in Internal Backend}

In the internal backend, the H2O cluster is created automatically during the call of \texttt{H2OContext.getOrCreate}. Since
it is not technically possible to get the number of executors in Spark, Sparkling Water tries to discover all executors
during the initiation of \texttt{H2OContext} and starts H2O instance inside each of discovered executors. This solution
is the easiest to deploy; however when Spark or YARN kills the executor, the whole H2O cluster goes down since H2O
does not support high availability. Also, there are cases where Sparkling Water is not able to discover all Spark
executors and will start just on the subset of executors. The shape of the cluster can not be changed later.
Internal backend is the default backend for Sparkling Water. It can be changed via spark configuration property
\texttt{spark.ext.h2o.backend.cluster.mode} to \textbf{external} or \textbf{internal}. Another way how to change the
type of backend is by calling \texttt{setExternalClusterMode()} or \texttt{setInternalClusterMode()} method
on \texttt{H2OConf} class instance. \texttt{H2OConf} is a simple wrapper around \texttt{SparkConf} and inherits all
properties in spark configuration.

\texttt{H2OContext} can be started as:

\begin{itemize}
    \item \textbf{Scala} \begin{lstlisting}[style=Scala]
import org.apache.spark.h2o._
val conf = new H2OConf().setInternalClusterMode()
val h2oContext = H2OContext.getOrCreate(conf)
    \end{lstlisting}
    \item \textbf{Python} \begin{lstlisting}[style=Python]
from pysparkling import *
conf = H2OConf().setInternalClusterMode()
h2oContext = H2OContext.getOrCreate(conf)
    \end{lstlisting}
    \item \textbf{R} \begin{lstlisting}[style=R]
library(sparklyr)
library(rsparkling)
spark_connect(master = "local", version = "3.0.0")
conf <- H2OConf()$setInternalClusterMode()
h2oContext <- H2OContext.getOrCreate(conf)
    \end{lstlisting}
\end{itemize}

If \texttt{spark.ext.h2o.backend.cluster.mode} property was set to \textbf{internal} either on the command line or
on the \texttt{SparkConf}, the following call is sufficient

\begin{itemize}
    \item \textbf{Scala} \begin{lstlisting}[style=Scala]
import org.apache.spark.h2o._
val h2oContext = H2OContext.getOrCreate()
    \end{lstlisting}
    \item \textbf{Python} \begin{lstlisting}[style=Python]
from pysparkling import *
h2oContext = H2OContext.getOrCreate()
    \end{lstlisting}
    \item \textbf{R} \begin{lstlisting}[style=R]
library(sparklyr)
library(rsparkling)
spark_connect(master = "local", version = "3.0.0")
h2oContext <- H2OContext.getOrCreate()
    \end{lstlisting}
\end{itemize}

\subsection{External Backend}

In the external cluster, we use the H2O cluster running separately from the rest of the Spark application. This separation
gives us more stability because we are no longer affected by Spark executors being killed, which can
lead (as in the previous mode) to h2o cluster being killed as well.

There are two deployment strategies of the external cluster: manual and automatic. In manual mode, we need to start
the H2O cluster, and in the automatic mode, the cluster is started for us automatically based on our configuration.
In Hadoop environments, the creation of the cluster is performed by a simple process called H2O driver.
When the cluster is fully formed, the H2O driver terminates. In both modes, we have to store a path of H2O driver jar
to the environment variable H2O\_DRIVER\_JAR.

\begin{lstlisting}[style=bash]
H2O_DRIVER_JAR=$(./bin/get-h2o-driver.sh some_hadoop_distribution)
\end{lstlisting}

\subsubsection{Automatic Mode of External Backend}

In the automatic mode, the H2O cluster is started automatically. The cluster can be started automatically only in YARN
environment at the moment. We recommend this approach, as it is easier to deploy external clusters in this mode,
and it is also more suitable for production environments. When the H2O cluster is started on YARN, it is started
as a map-reduce job, and it always uses the flat-file approach for nodes to cloud up.

First, get H2O driver, for example, for cdh 5.8, as:

\begin{lstlisting}[style=bash]
H2O_DRIVER_JAR=$(./bin/get-h2o-driver.sh cdh5.8)
\end{lstlisting}


To start an H2O cluster and connect to it, run:

\begin{itemize}
    \item \textbf{Scala} \begin{lstlisting}[style=Scala]
import org.apache.spark.h2o._
val conf = new H2OConf()
    .setExternalClusterMode()
    .useAutoClusterStart()
    .setH2ODriverPath("path_to_h2o_driver")
    .setClusterSize(1)
    .setMapperXmx("2G")
    .setYARNQueue("abc")
val hc = H2OContext.getOrCreate(conf)
    \end{lstlisting}
    \item \textbf{Python} \begin{lstlisting}[style=Python]
from pysparkling import *
conf = H2OConf()
    .setExternalClusterMode()
    .useAutoClusterStart()
    .setH2ODriverPath("path_to_h2o_driver")
    .setClusterSize(1)
    .mapperXmx("2G")
    .setYARNQueue("abc")
hc = H2OContext.getOrCreate(conf)
    \end{lstlisting}
    \item \textbf{R} \begin{lstlisting}[style=R]
library(sparklyr)
library(rsparkling)
spark_connect(master = "local", version = "3.0.0")
conf <- H2OConf()
    $setExternalClusterMode()
    $useAutoClusterStart()
    $setH2ODriverPath("path_to_h2o_driver")
    $setClusterSize(1)
    $setMapperXmx("2G")
    $setYARNQueue("abc")
hc <- H2OContext.getOrCreate(conf)
    \end{lstlisting}
\end{itemize}

In case we stored the path of the driver H2O jar to environmental variable H2O\_DRIVER\_JAR, we do not need
to call \texttt{setH2ODriverPath} as Sparkling Water will read the path from the environmental variable.

When specifying the queue, we recommend that this queue has YARN preemption off to have a stable H2O cluster.

In the case of Scala, it can also happen that we might need to explicitly set the client's IP or network. To see how this
can be configured, please see the section \ref{subsection:specify_ip}.

\subsubsection{Manual Mode of External Backend on Hadoop}

In the manual mode, we need to start the H2O cluster before connecting to it manually. At this section, we
will start the cluster on Hadoop.

First, get the H2O driver, for example, for cdh 5.8, as:

\begin{lstlisting}[style=bash]
H2O_DRIVER_JAR=$(./bin/get-h2o-driver.sh cdh5.8)
\end{lstlisting}

Also, set path to sparkling-water-assembly-extensions-2.12-all.jar which is bundled in Sparkling Water for Spark 3.0 archive.

\begin{lstlisting}[style=bash]
SW_EXTENSIONS_ASSEMBLY=/path/to/sparkling-water-3.30.0.7-1-3.0/jars/sparkling-water-assembly-extensions_2.12-3.30.0.7-1-2.4-all.jar
\end{lstlisting}

Let's start the H2O cluster on Hadoop:

\begin{lstlisting}[style=bash]
hadoop -jar $H2O_DRIVER_JAR -libjars $SW_EXTENSIONS_ASSEMBLY -sw_ext_backend -jobname test -nodes 3 -mapperXmx 6g
\end{lstlisting}

The \texttt{-sw\_ext\_backend} option is required as without it, the cluster won't allow Sparkling Water client to connect to it.

After this step, we should have an H2O cluster with 3 nodes running on Hadoop.

To connect to this external cluster, run the following commands:

\begin{itemize}
    \item \textbf{Scala} \begin{lstlisting}[style=Scala]
import org.apache.spark.h2o._
val conf = new H2OConf()
    .setExternalClusterMode()
    .useManualClusterStart()
    .setH2OCluster("representant_ip", representant_port)
    .setCloudName("test")
val hc = H2OContext.getOrCreate(conf)
    \end{lstlisting}
    \item \textbf{Python} \begin{lstlisting}[style=Python]
from pysparkling import *
conf = H2OConf()
    .setExternalClusterMode()
    .useManualClusterStart()
    .setH2OCluster("representant_ip", representant_port)
    .setCloudName("test")
hc = H2OContext.getOrCreate(conf)
    \end{lstlisting}
    \item \textbf{R} \begin{lstlisting}[style=R]
library(sparklyr)
library(rsparkling)
spark_connect(master = "local", version = "3.0.0")
conf <- H2OConf()
    $setExternalClusterMode()
    $useManualClusterStart()
    $setH2OCluster("representant_ip", representant_port)
    $setCloudName("test")
hc <- H2OContext.getOrCreate(conf)
    \end{lstlisting}
\end{itemize}


The \texttt{representant\_ip} and \texttt{representant\_port} should be IP and port of the leader node of the started
H2O cluster from the previous step.

\subsubsection{Manual Mode of External Backend without Hadoop (standalone)}

In the manual mode, we need to start the H2O cluster before connecting to it manually. At this section, we will start
the cluster as a standalone application (without Hadoop).

First, get the assembly H2O Jar:

\begin{lstlisting}[style=bash]
H2O_JAR=$(./bin/get-h2o-driver.sh standalone)
\end{lstlisting}

.. code:: bash


Also, set path to sparkling-water-assembly-extensions-2.12-all.jar which is bundled in Sparkling Water for Spark 3.0 archive.

\begin{lstlisting}[style=bash]
SW_EXTENSIONS_ASSEMBLY=/path/to/sparkling-water-3.30.0.7-1-3.0/jars/sparkling-water-assembly-extensions_2.12-3.30.0.7-1-2.4-all.jar
\end{lstlisting}

To start an external H2O cluster, run:

\begin{lstlisting}[style=bash]
java -cp "$H2O_JAR:$SW_EXTENSIONS_ASSEMBLY" water.H2OApp -allow_clients -name test -flatfile path_to_flatfile
\end{lstlisting}


where the flat-file content are lines in the format of ip:port of the nodes where H2O is supposed to run. To
read more about flat-file and its format, please
see \url{https://github.com/h2oai/h2o-3/blob/master/h2o-docs/src/product/howto/H2O-DevCmdLine.md#flatfile}.


To connect to this external cluster, run the following commands:

\begin{itemize}
    \item \textbf{Scala} \begin{lstlisting}[style=Scala]
import org.apache.spark.h2o._
val conf = new H2OConf()
    .setExternalClusterMode()
    .useManualClusterStart()
    .setH2OCluster("representant_ip", representant_port)
    .setCloudName("test")
val hc = H2OContext.getOrCreate(conf)
    \end{lstlisting}
    \item \textbf{Python} \begin{lstlisting}[style=Python]
from pysparkling import *
conf = H2OConf()
    .setExternalClusterMode()
    .useManualClusterStart()
    .setH2OCluster("representant_ip", representant_port)
    .setCloudName("test")
hc = H2OContext.getOrCreate(conf)
    \end{lstlisting}
    \item \textbf{R} \begin{lstlisting}[style=R]
library(sparklyr)
library(rsparkling)
spark_connect(master = "local", version = "3.0.0")
conf <- H2OConf()
    $setExternalClusterMode()
    $useManualClusterStart()
    $setH2OCluster("representant_ip", representant_port)
    $setCloudName("test")
hc <- H2OContext.getOrCreate(conf)
    \end{lstlisting}
\end{itemize}

The \texttt{representant\_ip} and \texttt{representant\_port} should be IP and port of the leader node of the started
H2O cluster from the previous step.

\subsection{Specifying the Client Network in Scala}
\label{subsection:specify_ip}

It is possible that Spark driver, in which we are running H2O client which is connecting to the external H2O cluster, is
connected to multiple networks. This can happen only in Scala as Python and R clients are not using the H2O client.

In this case, external H2O cluster may decide to use addresses from network A while Spark decides to use
addresses for its executors and driver from network B. When we start \textbf{H2OContext}, the H2O
client running inside of the Spark Driver can get the same IP address as the Spark driver, and, thus, the rest
of the H2O cluster can't see it. This shouldn't happen in environments where the nodes are connected to only one
network; however we provide a configuration for how to deal with this case as well.

Let's assume we have two H2O nodes on addresses 192.168.0.1 and 192.168.0.2. Let's also assume that the Spark driver
is available on 172.16.1.1, and the only executor is available on 172.16.1.2. The node with the Spark driver
is also connected to the 192.168.0.x network with address 192.168.0.3.

In this case, there is a chance that the H2O client will use the address from 172.16.x.x network instead
of the 192.168.0.x one, which can lead to the problem that the H2O cluster and H2O client can't see each other.

We can force the client to use the correct network or address using the calling \textbf{setClientNetworkMask("192.168.0.0/24")}
on \textbf{H2OConf} object. Instead of \textbf{setClientNetworkMask}, we can also use more strict variant and specify
the IP address directly using \textbf{setClientIp("192.168.0.3")}. This IP address needs to be accessible from the
Spark driver and needs to be located in the same network as the rest of the H2O worker nodes.

\subsection{Memory Management}

In the case of the internal backend, H2O resides in the same executor JVM as Spark and the memory provided for H2O is configured
via Spark.
Executor memory (i.e., memory available for H2O in internal backend) can be configured via the Spark configuration
property \texttt{spark.executor.memory}. For example, as:

\begin{lstlisting}[style=bash]
./bin/sparkling-shell --conf spark.executor.memory=5g
\end{lstlisting}

or configure the property in:

\begin{lstlisting}[style=bash]
$SPARK_HOME/conf/spark-defaults.conf
\end{lstlisting}

Driver memory (i.e., memory available for H2O client running inside the Spark driver) can be configured via the Spark
configuration property \texttt{spark.driver.memory}. For example, as:

\begin{lstlisting}[style=bash]
./bin/sparkling-shell --conf spark.driver.memory=5g
\end{lstlisting}

or configure the property in:

\begin{lstlisting}[style=bash]
$SPARK_HOME/conf/spark-defaults.conf
\end{lstlisting}

In the external backend, only the H2O client (Scala only) is running in the Spark driver and is affected by Spark
memory configuration. Memory has to be configured explicitly for the H2O nodes in the external backend via the
\texttt{spark.ext.h2o.hadoop.memory} option or \texttt{setMapperXmx} setter on \texttt{H2OConf}.

For YARN-specific configuration, refer to the Spark documentation \url{https://spark.apache.org/docs/latest/running-on-yarn.html}.
