\section{What is PySparkling Water?}

PySparkling Water is an integration of Python with Sparkling water. It allows the user to start H2O services on a spark cluster from Python API.

In the PySparkling Water driver program, the \texttt{SparkContext} or \texttt{SparkSession} uses Py4J to start the driver JVM, and the JAVA \texttt{SparkContext}/\texttt{SparkSession} is used to create \texttt{H2OContext} (hc). This in turn starts the H2O cluster in the Spark ecosystem. (In Internal backend only. In external backend, the H2O cluster is running outside of the Spark cluster.)
Once the H2O cluster is up, the H2O-Python package is used to interact with the cluster and run H2O algorithms. All pure H2O calls are executed via H2O's REST API interface. Users can easily integrate their regular PySpark workflow with H2O algorithms using PySparkling Water.

PySparkling Water programs can be launched as an application, or in an interactive shell, or notebook environment.

\subsection{Getting Started:}

\begin{enumerate}
\item Download Spark (if not already installed) from the Spark Downloads Page.

Choose Spark release : 2.2.0

Choose a package type: Pre-built for Hadoop 2.4 and later

\item Point SPARK\_HOME to the existing installation of Spark and export variable MASTER.

\begin{lstlisting}[style=Bash]
export SPARK_HOME="/path/to/spark/installation" 
\end{lstlisting}

Launch a local Spark cluster.
\begin{lstlisting}[style=Bash]
export MASTER="local[*]"
\end{lstlisting}

\item From your terminal, run:

\begin{lstlisting}[style=Bash]
cd ~/Downloads
unzip sparkling-water-2.2.2.zip
cd sparkling-water-2.2.2
\end{lstlisting}

Start an interactive Python terminal:
\begin{lstlisting}[style=Bash]
bin/pysparkling
\end{lstlisting}
The pysparkling shell accepts common pyspark arguments.

Or start a notebook:
\begin{lstlisting}[style=Bash]
PYSPARK_DRIVER_PYTHON="ipython" PYSPARK_DRIVER_PYTHON_OPTS="notebook" bin/pysparkling
\end{lstlisting}

\item Create an H2O cluster inside the Spark cluster and import H2O-Python package:

\begin{lstlisting}[style=Python]
from pysparkling import *
hc = H2OContext.getOrCreate(spark)
import h2o
\end{lstlisting}

\item Follow this demo, which imports Chicago crime, census, and weather data. It also predicts the probability of arrest:
 \url{https://github.com/h2oai/h2o-world-2015-training/blob/master/tutorials/pysparkling/Chicago_Crime_Demo.ipynb}

\end{enumerate}

Alternatively, to launch on YARN:

\begin{lstlisting}[style=Bash]
wget http://h2o-release.s3.amazonaws.com/sparkling-water/rel-2.2/2/sparkling-water-2.2.2.zip
unzip sparkling-water-2.2.2.zip
 
export SPARK_HOME="/path/to/spark/installation"
export HADOOP_CONF_DIR=/etc/hadoop/conf
export SPARKLING_HOME="/path/to/SparklingWater/installation"
$SPARKLING_HOME/bin/pysparkling --num-executors 3 --executor-memory 20g --executor-cores 10 --driver-memory 20g --master yarn --deploy-mode client
\end{lstlisting}
    
Then create an H2O cluster inside the Spark cluster and import H2O-Python package:
\begin{lstlisting}[style=Python]
from pysparkling import *
hc = H2OContext.getOrCreate(spark)
import h2o
\end{lstlisting}

Or to launch as a Spark Package application:
\begin{lstlisting}[style=Bash]
$SPARK_HOME/bin/spark-submit --py-files $SPARKLING_HOME/py/build/dist/h2o_pysparkling_2.2-2.2.2.zip
$SPARKLING_HOME/py/examples/scripts/H2OContextInitDemo.py
\end{lstlisting}


\subsection{Using Spark Data Sources}

The way that an \texttt{H2OFrame} can be used as Spark's data source differs a little bit in Python from Scala.

\subsubsection{Reading from \texttt{H2OFrame}}

Let's suppose we have an \texttt{H2OFrame}. There are two ways how the \texttt{DataFrame} can be loaded from \texttt{H2OFrame} in pySparkling:
\begin{lstlisting}[style=Scala]
df = spark.read.format("h2o").option("key", frame.frame_id).load()
\end{lstlisting}
or
\begin{lstlisting}[style=Scala]
df = spark.read.format("h2o").load(frame.frame_id)
\end{lstlisting}

\subsubsection{Saving to \texttt{H2OFrame}}

Let's suppose we have a \texttt{DataFrame} df. There are two ways how \texttt{DataFrame} can be saved as 
\texttt{H2OFrame} in pySparkling:

\begin{lstlisting}[style=Scala]
df.write.format("h2o").option("key", "new_key").save()
\end{lstlisting}
or
\begin{lstlisting}[style=Scala]
df.write.format("h2o").save("new_key")
\end{lstlisting}

Both variants save \texttt{DataFrame} as an \texttt{H2OFrame} with key \texttt{new\_key}. They won't succeed if an \texttt{H2OFrame} with the same key already exists.

\subsubsection{Loading and Saving Options}

If the key is specified as 'key' option, and also in the load/save method, the option 'key' is preferred:
\begin{lstlisting}[style=Scala]
df = spark.read.from("h2o").option("key", "key_one").load("key_two")
\end{lstlisting}
or
\begin{lstlisting}[style=Scala]
df = spark.read.from("h2o").option("key", "key_one").save("key_two")
\end{lstlisting}

In both examples, \texttt{key\_one} is used.

