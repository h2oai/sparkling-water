package ai.h2o.sparkling.repl

import java.io.File

import org.apache.spark.expose.Utils
import org.apache.spark.repl.Main
import org.apache.spark.{SparkConf, SparkContext, SparkEnv}

import scala.tools.nsc.interpreter.Naming

/**
  * Helper methods for H2OIMain on both scala versions
  */
trait H2OIMainHelper {

  private var _initialized = false

  /**
    * Ensure that each class defined in REPL is in a package containing number of repl session
    */
  def setupClassNames(naming: Naming, sessionId: Int): Unit = {
    import naming._
    // sessionNames is lazy val and needs to be accessed first in order to be then set again to our desired value
    naming.sessionNames.line
    val fieldSessionNames = naming.getClass.getDeclaredField("sessionNames")
    fieldSessionNames.setAccessible(true)
    fieldSessionNames.set(naming, new SessionNames {
      override def line = "intp_id_" + sessionId + propOr("line")
    })

    // FIX for SW-386
    // We need to patch OuterScopes regexp to correctly recognize classes generated by H2O REPL
    PatchUtils.PatchManager.patch("SW-386", Thread.currentThread().getContextClassLoader)
  }

  def setClassLoaderToSerializers(classLoader: ClassLoader): Unit = {
    SparkEnv.get.serializer.setDefaultClassLoader(classLoader)
    SparkEnv.get.closureSerializer.setDefaultClassLoader(classLoader)
  }

  def newREPLDirectory(): File = {
    val conf = new SparkConf()
    val rootDir = conf.getOption("spark.repl.classdir").getOrElse(Utils.getLocalDir(conf))
    val outputDir = Utils.createTempDir(root = rootDir, namePrefix = "repl")
    outputDir
  }

  def initializeClassLoader(sc: SparkContext): Unit = {
    if (!_initialized) {
      if (Main.interp != null) {
        // Application has been started using SparkShell script.
        // Set the original interpreter classloader as the fallback class loader for all
        // class not defined in our custom REPL.
        setClassLoaderToSerializers(new InterpreterClassLoader(Main.interp.intp.classLoader))
      } else {
        // Application hasn't been started using SparkShell.
        // Set the context classloader as the fallback class loader for all
        // class not defined in our custom REPL
        setClassLoaderToSerializers(new InterpreterClassLoader(Thread.currentThread.getContextClassLoader))
      }
      _initialized = true
    }
  }
}
